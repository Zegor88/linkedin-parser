{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aaf5078-9e44-40a5-99a9-a3d7a802dc11",
   "metadata": {},
   "source": [
    "### Connection to LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9e13de-c61b-4e1d-96e3-26a606db29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb11c510-8789-4ad8-8274-73b65efc8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6964268b-c983-481d-83ec-442e0a6c6c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вход в LinkedIn, войти | LinkedIn'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.linkedin.com/login')\n",
    "time.sleep(2)\n",
    "driver.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3013317-0892-4fa0-942d-9e4d06919dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** LOG IN *************\n",
    "\n",
    "email = driver.find_element(By.ID, 'username')\n",
    "password = driver.find_element(By.ID, 'password')\n",
    "\n",
    "email.send_keys(os.environ['LINKEDIN_EMAIL'])\n",
    "password.send_keys(os.environ['LINKEDIN_PASSWORD'])\n",
    "\n",
    "password.submit()\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4db4b09-85bc-4cb7-b42d-724b637cddd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1) Egor Zubenko | LinkedIn'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#********** GO TO PROFILE *************\n",
    "url = \"https://www.linkedin.com/in/zubenkoey/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "driver.title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbbe440-56a7-4d73-955b-117a11d63810",
   "metadata": {},
   "source": [
    "### Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e207a-729c-4944-bdd0-d118d0131b55",
   "metadata": {},
   "source": [
    "#### Name and Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1dbb79-5eb4-4ea8-986f-e5551f084d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Egor Zubenko',\n",
       " 'url': 'https://www.linkedin.com/in/zubenkoey/',\n",
       " 'headline': 'Business System Analyst @ Webvork | Python, SQL, OpenAI'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_data = {}\n",
    "\n",
    "#********** GET NAME *************\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "name = soup.find('h1', {'class': 'REcVsMzJIjWGrvfwbuhgiUDStqsxZjeKqIQFB inline t-24 v-align-middle break-words'}).get_text()\n",
    "\n",
    "#********** GET HEADLINE *************\n",
    "headline = soup.find('div', {'class': 'text-body-medium break-words'})\n",
    "headline = headline.get_text().strip()\n",
    "\n",
    "profile_data['name'] = name\n",
    "profile_data['url'] = url\n",
    "profile_data['headline'] = headline\n",
    "\n",
    "profile_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13d931-15b7-4f62-99ab-88d30fa94111",
   "metadata": {},
   "source": [
    "#### About"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0b9db1-b2a4-47a1-bebc-1e048b103612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Egor Zubenko',\n",
       " 'url': 'https://www.linkedin.com/in/zubenkoey/',\n",
       " 'headline': 'Business System Analyst @ Webvork | Python, SQL, OpenAI',\n",
       " 'About': \"I'm an Analyst with a strong background in the upstream sector of Oil&Gas industry as a Petroleum Engineer, and Business Analysis for IT projects. Currently, I am involved in various IT projects, such as conducting a comprehensive CRM system analysis, proposing a new algorithm for assigning orders to call center operators, and describing a system feature that enables data-driven decision making. I would like to move on and develop in the field of business and data analysis, implement AI solutions and develop IT products.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#********** GET ABOUT INFO *************\n",
    "\n",
    "xPath = '//*[@id=\"profile-content\"]/div/div[2]/div/div/main/section[4]/div[3]/div/div/div/span[1]'\n",
    "\n",
    "try:\n",
    "    # Locate the element\n",
    "    element = driver.find_element(By.XPATH, xPath)\n",
    "    text = element.text\n",
    "    profile_data['About'] = text\n",
    "except Exception as e:\n",
    "    print(\"Error finding the About section:\", e)\n",
    "\n",
    "profile_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9786cdd-15ab-4115-8c7b-3d94298f2348",
   "metadata": {},
   "source": [
    "#### Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c556f089-536b-4535-9605-85b3021c6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** GO TO EXPERIENCE PAGE *************\n",
    "\n",
    "driver.get('https://www.linkedin.com/in/zubenkoey/details/experience/')\n",
    "time.sleep(2)\n",
    "\n",
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6baf8a6a-6ee7-4678-83c8-b02d26f5590d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#********** EXTRACT EXPERIENCE *************\n",
    "\n",
    "# Предположим, что page_source содержит HTML-код страницы\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "# Находим все секции опыта\n",
    "sections = soup.find_all('li', class_='pvs-list__paged-list-item')\n",
    "\n",
    "# Создаем список для хранения данных\n",
    "experience_data = []\n",
    "\n",
    "# Проходим по всем секциям и извлекаем данные\n",
    "for sec in sections:\n",
    "    # Извлекаем название компании\n",
    "    company_tag = sec.find('span', class_='t-14 t-normal')\n",
    "    company_name = company_tag.get_text(strip=True).split('·')[0] if company_tag else 'N/A'\n",
    "    \n",
    "    # Извлекаем должность\n",
    "    position_tag = sec.find('div', class_='display-flex align-items-center mr1 t-bold')\n",
    "    position_name = position_tag.get_text(strip=True).split('·')[0] if position_tag else 'N/A'\n",
    "\n",
    "    # Извлекаем должность\n",
    "    working_period_tag = sec.find('span', class_='pvs-entity__caption-wrapper')\n",
    "    working_period = working_period_tag.get_text(strip=True).split('·')[0] if working_period_tag else 'N/A'\n",
    "\n",
    "    # Длительность\n",
    "    duration_tag = sec.find('span', class_='pvs-entity__caption-wrapper')\n",
    "    duration = duration_tag.get_text(strip=True).split('·')[1] if duration_tag else 'N/A'\n",
    "\n",
    "    # Находим все элементы внутри ul/li\n",
    "    list_items = sec.find_all('li', class_='pvs-list__item--with-top-padding')\n",
    "    \n",
    "    # Description\n",
    "    description = list_items[0].get_text(strip=True) if len(list_items) > 0 else 'N/A'\n",
    "\n",
    "    # Skills\n",
    "    skills = list_items[1].get_text(strip=True) if len(list_items) > 1 else 'N/A'\n",
    "\n",
    "    \n",
    "    # Сохраняем в список\n",
    "    experience_data.append({\n",
    "        'company': company_name,\n",
    "        'position': position_name,\n",
    "        'workin_period': working_period,\n",
    "        'duration': duration,\n",
    "        'description': description,\n",
    "        'skills': skills,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1829ce8-ab63-4fd4-8120-f359a4872f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data['Experience'] = experience_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37788a6-a034-42b0-96d4-a32763169989",
   "metadata": {},
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3643f2aa-f6d5-4262-808d-f0c8e7ab1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** GO TO EDUCATION PAGE *************\n",
    "\n",
    "driver.get('https://www.linkedin.com/in/zubenkoey/details/education/')\n",
    "time.sleep(2)\n",
    "\n",
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51fa5ae7-1994-43de-9be9-25f0a91087d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University: Heriot-Watt University\n",
      "Degree: Master of Science (MSc), Petroleum Engineering\n",
      "Dates: 2015 - 2016\n",
      "Details:\n",
      "  - Activities and societies: Participant of the best Field Development Project (1st place)\n",
      "  - Graduation thesis: “Uncertainty reduction of drilling wells at the Field A”\n",
      "  - Skills: Oil and Gas Engineering · Reservoir Engineering · Oil & Gas\n",
      "  - Diploma\n",
      "Certificates/Media:\n",
      "  - Heriot-Watt University\n",
      "  - Diploma\n",
      "\n",
      "\n",
      "University: Peter the Great St.Petersburg Polytechnic University\n",
      "Degree: Postgraduate Degree, Intelligent Systems\n",
      "Dates: Feb 2023 - Jun 2023\n",
      "Details:\n",
      "  - Grade: A\n",
      "  - Activities and societies: - High-level Design of Information Control Systems - Project Management - Corporate Information Systems - Intelligent Systems - Software Development Technologies (ML) - Group Project: Safety Helmet Detection expert system - Individual Project: Modelling the system of Permeate neutralisation plant N1\n",
      "  - A Group Project goal Develop an expert system for recognizing the wearing of safety helmets based on incoming data (photo) that returns a response within an acceptable time frame and with minimal losses. Tasks: - Create use case, swimlane, IDEF0 diagrams - Choose an appropriate architecture - Train a model (Yolo5, CNN) - Create a telegram bot and apply a chosen model Additionally, completed an individual project modeling high-level and low-level design for the Permeate Neutralisation Plant N1 using UML and CodeSys, enhancing skills in system analysis and automation.\n",
      "  - Skills: Python · Business Analytics\n",
      "  - Human Machine Interface - Individual Project\n",
      "  - Application of the models - Group Project\n",
      "  - Certificate\n",
      "Certificates/Media:\n",
      "  - Peter the Great St.Petersburg Polytechnic University\n",
      "  - Human Machine Interface - Individual Project\n",
      "  - Application of the models - Group Project\n",
      "  - Certificate\n",
      "\n",
      "\n",
      "University: Tomsk Polytechnic University\n",
      "Degree: Магистр/ MSc, Разработка нефтяных и газовых месторождений/ Reservoir Engineering\n",
      "Dates: 2005 - 2011\n",
      "Details:\n",
      "  - Skills: Oil and Gas Engineering · Reservoir Engineering\n",
      "Certificates/Media:\n",
      "  - Tomsk Polytechnic University\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#********** EXTRACT EDUCATION *************\n",
    "\n",
    "# Предположим, что html_data содержит HTML-код секции Education\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "# Находим секцию Education\n",
    "education_section = soup.find('div', class_='pvs-list__container')\n",
    "\n",
    "# Список для хранения данных\n",
    "education_data = []\n",
    "\n",
    "# Проверяем, найдена ли секция Education\n",
    "if education_section:\n",
    "    # Находим все элементы образования\n",
    "    education_items = education_section.find_all('li', class_='pvs-list__paged-list-item')\n",
    "    \n",
    "    for item in education_items:\n",
    "        # Извлечение названия университета\n",
    "        university_tag = item.find('div', class_='display-flex align-items-center mr1 hoverable-link-text t-bold')\n",
    "        university = 'N/A'\n",
    "        if university_tag:\n",
    "            span = university_tag.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                university = span.get_text(strip=True)\n",
    "        \n",
    "        # Извлечение степени и направления\n",
    "        degree_tag = item.find('span', class_='t-14 t-normal')\n",
    "        degree = 'N/A'\n",
    "        if degree_tag:\n",
    "            span = degree_tag.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                degree = span.get_text(strip=True)\n",
    "        \n",
    "        # Извлечение дат обучения\n",
    "        dates_tag = item.find('span', class_='t-14 t-normal t-black--light')\n",
    "        dates = 'N/A'\n",
    "        if dates_tag:\n",
    "            span = dates_tag.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                dates = span.get_text(strip=True)\n",
    "        \n",
    "        # Извлечение описания и проектов\n",
    "        details = []\n",
    "        # Находим все элементы li внутри текущего образования\n",
    "        detail_items = item.find_all('li', class_='OxttavmlcaTTQyNiTiLxfszAmvmHtRgbWzWcY')\n",
    "        for detail in detail_items:\n",
    "            # Извлекаем только первый span с aria-hidden=true\n",
    "            span = detail.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                text = span.get_text(separator=' ', strip=True)\n",
    "                # Добавляем только если текст не пустой и не дублируется\n",
    "                if text and text not in details:\n",
    "                    details.append(text)\n",
    "        \n",
    "        # Извлечение сертификатов или медиа (если есть)\n",
    "        certificates = []\n",
    "        # Внутри item, ищем все 'a' с class='optional-action-target-wrapper', но исключаем 'edit' и 'view reorder'\n",
    "        media_links = item.find_all('a', class_='optional-action-target-wrapper')\n",
    "        for media in media_links:\n",
    "            aria_label = media.get('aria-label', '').lower()\n",
    "            if 'edit education' in aria_label or 'view education reorder screen' in aria_label:\n",
    "                continue  # пропускаем ссылки на редактирование и сортировку\n",
    "            # Извлекаем только span с aria-hidden=true внутри 'a'\n",
    "            span = media.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                media_text = span.get_text(strip=True)\n",
    "                if media_text and media_text not in certificates:\n",
    "                    certificates.append(media_text)\n",
    "        \n",
    "        # Сохраняем данные\n",
    "        education_data.append({\n",
    "            'university': university,\n",
    "            'degree': degree,\n",
    "            'dates': dates,\n",
    "            'details': details,\n",
    "            'certificates': certificates\n",
    "        })\n",
    "\n",
    "# Выводим результаты\n",
    "for edu in education_data:\n",
    "    print(f\"University: {edu['university']}\")\n",
    "    print(f\"Degree: {edu['degree']}\")\n",
    "    print(f\"Dates: {edu['dates']}\")\n",
    "    print(\"Details:\")\n",
    "    for detail in edu['details']:\n",
    "        print(f\"  - {detail}\")\n",
    "    if edu['certificates']:\n",
    "        print(\"Certificates/Media:\")\n",
    "        for cert in edu['certificates']:\n",
    "            print(f\"  - {cert}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21e671a6-df76-4b46-8f74-12569f155c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data['Education'] = education_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c750619-2835-4fa1-b6e3-a2218f7b96a5",
   "metadata": {},
   "source": [
    "#### Licenses & certifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4876750-cc35-4646-8ffb-971eb341fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** GO TO Licenses & certifications PAGE *************\n",
    "\n",
    "driver.get('https://www.linkedin.com/in/zubenkoey/details/certifications/')\n",
    "time.sleep(2)\n",
    "\n",
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00e2bb21-6c27-43fc-b08c-c6e3c0e77547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** CHECK THE Licenses & certifications PAGE *************\n",
    "\n",
    "# soup = BeautifulSoup(page_source, 'lxml')\n",
    "# sections = soup.find_all('div', {'class': 'scaffold-finite-scroll__content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8909833-2c31-415b-85bf-7e5daccff09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'certification_name': 'Build a Machine Learning Model Skill Path', 'issuer': 'Codecademy', 'issue_date': 'Issued Nov 2024', 'credential_id': 'N/A', 'skills': 'Artificial Intelligence (AI) · Python', 'certificates_or_media': ['Build a Machine Learning Model Skill Path', 'Certificate | Codecademy.pdf', 'Ml_Capstone_Project at GitHub']}\n",
      "{'certification_name': 'AI Engineering Specialization', 'issuer': 'Scrimba', 'issue_date': 'Issued Mar 2024', 'credential_id': 'Credential ID GANNTUR4L26C', 'skills': 'Large Language Models (LLM) · Artificial Intelligence (AI) · Prompt Engineering', 'certificates_or_media': ['AI Engineering Specialization']}\n",
      "{'certification_name': 'Supply Chain Analytics Specialization', 'issuer': 'Rutgers University', 'issue_date': 'Issued Jan 2024', 'credential_id': 'Credential ID 4LXCK6T92GYY', 'skills': 'Inventory Analysis · Demand Forecasting · Supply Chain Risk Management · Business Analytics · Forecasting · Supply Chain', 'certificates_or_media': ['Supply Chain Analytics Specialization']}\n",
      "{'certification_name': 'IBM Data Analyst Specialization', 'issuer': 'IBM', 'issue_date': 'Issued Sep 2022', 'credential_id': 'Credential ID 68VUENLDVVJ5', 'skills': 'Python · Data Visualization (DataViz) · Microsoft Excel · Python Programming · Business Intelligence (BI) · Data Analysis · SQL', 'certificates_or_media': ['IBM Data Analyst Specialization']}\n",
      "{'certification_name': 'Google Project Management: Specialization', 'issuer': 'Google', 'issue_date': 'Issued May 2022', 'credential_id': 'Credential ID EQDFTKPMCPVT', 'skills': 'Lean Six Sigma', 'certificates_or_media': ['Google Project Management: Specialization']}\n"
     ]
    }
   ],
   "source": [
    "#********** EXTRACT Licenses & certifications *************\n",
    "\n",
    "# Предположим, что page_source содержит HTML-код страницы с сертификатами\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "# Находим все секции сертификатов\n",
    "sections = soup.find_all('div', {'class': 'scaffold-finite-scroll__content'})\n",
    "\n",
    "# Список для хранения данных о сертификатах\n",
    "certification_data = []\n",
    "\n",
    "# Итерация по каждой секции\n",
    "for section in sections:\n",
    "    # Находим все элементы сертификатов внутри секции\n",
    "    certification_items = section.find_all('li', class_='pvs-list__paged-list-item')\n",
    "    \n",
    "    for item in certification_items:\n",
    "        # Извлечение названия сертификата\n",
    "        name_tag = item.find('div', class_='display-flex align-items-center mr1 hoverable-link-text t-bold')\n",
    "        certification_name = 'N/A'\n",
    "        if name_tag:\n",
    "            span = name_tag.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                certification_name = span.get_text(strip=True)\n",
    "        \n",
    "        # Извлечение издателя (issuer)\n",
    "        issuer_tag = item.find('span', class_='t-14 t-normal')\n",
    "        issuer = 'N/A'\n",
    "        if issuer_tag:\n",
    "            span = issuer_tag.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                issuer = span.get_text(strip=True)\n",
    "        \n",
    "        # Извлечение даты выдачи\n",
    "        date_tag = item.find('span', class_='t-14 t-normal t-black--light')\n",
    "        issue_date = 'N/A'\n",
    "        if date_tag:\n",
    "            span = date_tag.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                issue_date = span.get_text(strip=True)\n",
    "        \n",
    "        # Извлечение Credential ID\n",
    "        credential_id_tag = item.find_all('span', class_='t-14 t-normal t-black--light')\n",
    "        credential_id = 'N/A'\n",
    "        if len(credential_id_tag) >= 2:\n",
    "            # Предполагается, что Credential ID находится во втором span\n",
    "            span = credential_id_tag[1].find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                credential_id = span.get_text(strip=True)\n",
    "        \n",
    "        # Извлечение навыков (Skills)\n",
    "        skills = 'N/A'\n",
    "        skills_container = item.find('div', class_='display-flex align-items-center t-14 t-normal t-black')\n",
    "        if skills_container:\n",
    "            skills_span = skills_container.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if skills_span:\n",
    "                # Извлекаем текст после \"Skills:\"\n",
    "                skills_text = skills_span.get_text(strip=True)\n",
    "                if 'Skills:' in skills_text:\n",
    "                    skills = skills_text.replace('Skills:', '').strip()\n",
    "        \n",
    "        # Извлечение сертификатов или медиа (если есть)\n",
    "        certificates = []\n",
    "        # Находим все 'a' теги с классом 'optional-action-target-wrapper' внутри сертификата\n",
    "        media_links = item.find_all('a', class_='optional-action-target-wrapper')\n",
    "        for media in media_links:\n",
    "            # Избегаем ссылок на редактирование или просмотр реорганизации\n",
    "            aria_label = media.get('aria-label', '').lower()\n",
    "            if 'edit certification' in aria_label or 'show credential' in aria_label:\n",
    "                continue  # пропускаем ссылки на редактирование и просмотр\n",
    "            # Извлекаем только span с aria-hidden=\"true\"\n",
    "            span = media.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                media_text = span.get_text(strip=True)\n",
    "                if media_text and media_text not in certificates:\n",
    "                    certificates.append(media_text)\n",
    "        \n",
    "        # Извлечение дополнительных деталей (например, Skills)\n",
    "        # В данном случае уже извлечены навыки, но если есть другие детали, можно их добавить\n",
    "        \n",
    "        # Сохранение данных о сертификате\n",
    "        certification_data.append({\n",
    "            'certification_name': certification_name,\n",
    "            'issuer': issuer,\n",
    "            'issue_date': issue_date,\n",
    "            'credential_id': credential_id,\n",
    "            'skills': skills,\n",
    "            'certificates_or_media': certificates\n",
    "        })\n",
    "\n",
    "# Вывод извлеченных данных\n",
    "for cert in certification_data:\n",
    "    print(cert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8779a07-58d5-457a-9460-08b63e347946",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data['Certification'] = certification_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8cf8b-7c4c-4d3c-b080-1014ed8dd333",
   "metadata": {},
   "source": [
    "#### Social MEdia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "416bfef6-a177-4285-9fe8-9014b369fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** GO TO MEDIA PAGE *************\n",
    "\n",
    "driver.get('https://www.linkedin.com/in/zubenkoey/recent-activity/all/')\n",
    "time.sleep(2)\n",
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edd2a056-0c12-4ade-8699-9f3f788b2228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Дата': '6d •6 days ago',\n",
       "  'Автор': 'Egor ZubenkoEgor Zubenko',\n",
       "  'Контент': 'Build a Machine Learning Model Skill Path fromCodecademy!So, it was useful to refresh my knowledge of regression, classification, and working with PyTorch and scikit-learn.',\n",
       "  'Реакции': '9Maksim Stepura and 8 others',\n",
       "  'Комментарии': '1 comment',\n",
       "  'Репосты': '0',\n",
       "  'Впечатления': 'N/A'},\n",
       " {'Дата': '1mo •1 month ago',\n",
       "  'Автор': 'Egor ZubenkoEgor Zubenko',\n",
       "  'Контент': 'It really sounds interesting ))\"\"\"Based on our interactions, it seems you have a strong interest in data analysis, AI systems, cryptography, and project management. A career path you might enjoy, which perhaps hasn’t crossed your mind, could be **AI Product Manager or AI Solutions Architect**.Here’s why:1. **AI Product Manager**: You already work with advanced analytics, machine learning, and agent-based systems like LangGraph and CrewAI. This role would allow you to combine your deep understanding of data, product development, and market trends. You’d focus on developing AI-driven products that optimize workflows, which aligns well with your interest in call center automation and optimizing operator efficiency.2. **AI Solutions Architect**: This position would involve designing and implementing AI systems tailored to specific business needs. Given your experience with automation projects, especially in logistics and call centers, you’d excel in crafting custom AI models that solve practical problems in CPA marketing or supplement production logistics.Both of these roles combine your technical expertise with strategic planning, and they allow you to leverage your knowledge of emerging technologies, particularly in AI and blockchain, to drive innovation within businesses.Does this path spark any new interest or ideas for you?\"\"\"…more',\n",
       "  'Реакции': '2Maksim Stepura and 1 other',\n",
       "  'Комментарии': '1 comment',\n",
       "  'Репосты': '0',\n",
       "  'Впечатления': 'N/A'},\n",
       " {'Дата': '8mo •9 months ago',\n",
       "  'Автор': 'Egor ZubenkoEgor Zubenko',\n",
       "  'Контент': 'I’m happy to share that I’ve obtained the AI Engineering course fromScrimbaand highly (!) recommend it.It gives not only theoretical knowledge but also practical skills in AI application development. The instructors and course materials are top! This course is beneficial for anyone looking to dive deeper into AI.P.S. I also had to start learning JavaScript from scratch to fully engage with the course content )))hashtag#LLMhashtag#AIEngineeringhashtag#ArtificialIntelligence…more',\n",
       "  'Реакции': '9',\n",
       "  'Комментарии': '6 comments',\n",
       "  'Репосты': '0',\n",
       "  'Впечатления': 'N/A'},\n",
       " {'Дата': '8mo •9 months ago',\n",
       "  'Автор': 'Egor ZubenkoEgor Zubenko',\n",
       "  'Контент': 'Hello!While working on a new feature of the system, I encountered a problem that I do not yet understand how to solve.So, there is a database that will be regularly updated and expanded with new content. Vectors are created using OpenAI tools (embedding), they are then saved in the database along with functionality for searching for similar vectors.❓The question itself is: How can we effectively maintain the relevance of these vectors, minimizing the need for their constant recalculation when changes are made to the content? Is it possible to use metadata, for example, by adding a timestamp to it?The structure of the table in the database is as follows:- id: a unique document identifier.- content: textual content of the document (in my case - chunk).- metadata: document metadata in JSONB format.- embedding: vector representation of the document with a dimension of 1536.…more',\n",
       "  'Реакции': '2',\n",
       "  'Комментарии': '0',\n",
       "  'Репосты': '0',\n",
       "  'Впечатления': 'N/A'},\n",
       " {'Дата': '1yr •1 year ago',\n",
       "  'Автор': 'Egor ZubenkoEgor Zubenko',\n",
       "  'Контент': \"🎓 Excited to announce that I've completed the Supply Chain Management Specialization byCourseraandRutgers Universityof New Jersey! 🚀 Studying onCourseraoffered a cool opportunity to expand skills while diving deeper into industries I work with. Looking forward to implementing this new knowledge in developing SCM systems!hashtag#SupplyChainManagementhashtag#LifelongLearnerhashtag#Courserahashtag#RutgersUniversity…more\",\n",
       "  'Реакции': '14',\n",
       "  'Комментарии': '2 comments',\n",
       "  'Репосты': '0',\n",
       "  'Впечатления': 'N/A'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#********** EXTRACT MEDIAs *************\n",
    "\n",
    "# Инициализация BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "# Находим контейнер всех постов\n",
    "sections = soup.find('div', {'class': 'scaffold-finite-scroll__content'})\n",
    "posts = sections.find_all('li', {'class': 'uZTLYReyXHzCftLccdpNxgzddhEgFKMTEnQ'})\n",
    "\n",
    "# Список для сохранения результатов\n",
    "data = []\n",
    "\n",
    "# Извлечение данных из каждого поста\n",
    "for post in posts:\n",
    "    try:\n",
    "        # Дата\n",
    "        date_element = post.find('a', {'class': 'update-components-actor__sub-description-link'})\n",
    "        date = date_element.get_text(strip=True) if date_element else None\n",
    "        \n",
    "        # Автор\n",
    "        author_element = post.find('span', {'class': 'NyBDmOsEjERFePrZbwKjouqNUZEwPnWBI'})\n",
    "        author = author_element.get_text(strip=True) if author_element else None\n",
    "        \n",
    "        # Контент\n",
    "        content_element = post.find('div', {'class': 'feed-shared-inline-show-more-text'})\n",
    "        content = content_element.get_text(strip=True) if content_element else None\n",
    "        \n",
    "        # Реакции\n",
    "        reactions_element = post.find('li', {'class': 'social-details-social-counts__reactions'})\n",
    "        reactions = reactions_element.get_text(strip=True) if reactions_element else None\n",
    "        \n",
    "        # Комментарии\n",
    "        comments_element = post.find('li', {'class': 'social-details-social-counts__comments'})\n",
    "        comments = comments_element.get_text(strip=True) if comments_element else None\n",
    "        \n",
    "        # Репосты (может быть отсутствовать)\n",
    "        reposts_element = post.find('button', {'aria-label': 'Repost'})\n",
    "        reposts = reposts_element.get_text(strip=True) if reposts_element else \"0\"\n",
    "        \n",
    "        # Впечатления (если есть аналитика)\n",
    "        impressions_element = post.find('strong', {'class': 'ca-entry-point__num-views'})\n",
    "        impressions = impressions_element.get_text(strip=True) if impressions_element else None\n",
    "\n",
    "        # Добавляем только те посты, где дата, автор и контент существуют\n",
    "        if date and author and content:\n",
    "            data.append({\n",
    "                'Дата': date,\n",
    "                'Автор': author,\n",
    "                'Контент': content,\n",
    "                'Реакции': reactions or \"0\",\n",
    "                'Комментарии': comments or \"0\",\n",
    "                'Репосты': reposts,\n",
    "                'Впечатления': impressions or \"N/A\"\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка обработки поста: {e}\")\n",
    "\n",
    "# Вывод данных\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad5ab4cc-e519-4d60-9d0b-a235f2cfd25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data['Posts'] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dcb4dc-d4ba-4cb8-aab4-ff5bfcdca4f3",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae5fe52a-1b21-476f-ac5e-96fc760d3f19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Egor Zubenko',\n",
       " 'url': 'https://www.linkedin.com/in/zubenkoey/',\n",
       " 'headline': 'Business System Analyst @ Webvork | Python, SQL, OpenAI',\n",
       " 'About': \"I'm an Analyst with a strong background in the upstream sector of Oil&Gas industry as a Petroleum Engineer, and Business Analysis for IT projects. Currently, I am involved in various IT projects, such as conducting a comprehensive CRM system analysis, proposing a new algorithm for assigning orders to call center operators, and describing a system feature that enables data-driven decision making. I would like to move on and develop in the field of business and data analysis, implement AI solutions and develop IT products.\",\n",
       " 'Experience': [{'company': 'Webvork ',\n",
       "   'position': 'Business System AnalystBusiness System Analyst',\n",
       "   'workin_period': 'Apr 2023 - Present ',\n",
       "   'duration': ' 1 yr 9 mos',\n",
       "   'description': \"As a Business Analyst and Data Specialist, I've leveraged my expertise in Python, SQL, and OpenAI's API to drive company profitability through meticulous data analysis and process optimization.Here's a snapshot of my core accomplishments:- Conducted a comprehensive CRM system analysis, delineating key features for system expansion into PMS, WMS, SCM, etc., and crafting a strategic roadmap for feature distribution across overlapping functionalities.- Designed and implemented agent-based and multi-agent systems utilizing RAG (Retrieval-Augmented Generation) with database integration capabilities, ensuring efficient data retrieval and analysis for decision-making processes.- Described a system feature that enables data forecasting using statistical methods (WMA, Exp.Smoothing) and ML (LR, ARIMA, RF). This functionality was applied for:- - KPI monitoring, including forecasting key indicators at the end of the accounting period.- - Forecasting demand and inventory levels of ingredients in warehouses, ensuring efficient inventory management.As a Business Analyst and Data Specialist, I've leveraged my expertise in Python, SQL, and OpenAI's API to drive company profitability through meticulous data analysis and process optimization.\\nHere's a snapshot of my core accomplishments:\\n- Conducted a comprehensive CRM system analysis, delineating key features for system expansion into PMS, WMS, SCM, etc., and crafting a strategic roadmap for feature distribution across overlapping functionalities.\\n- Designed and implemented agent-based and multi-agent systems utilizing RAG (Retrieval-Augmented Generation) with database integration capabilities, ensuring efficient data retrieval and analysis for decision-making processes.\\n- Described a system feature that enables data forecasting using statistical methods (WMA, Exp.Smoothing) and ML (LR, ARIMA, RF). This functionality was applied for:\\n - - KPI monitoring, including forecasting key indicators at the end of the accounting period.\\n - - Forecasting demand and inventory levels of ingredients in warehouses, ensuring efficient inventory management.\",\n",
       "   'skills': 'Skills:Forecasting · Large Language Models (LLM) · Python · Business Analytics · Business Intelligence (BI) · Artificial Intelligence (AI) · Prompt Engineering · Data Visualization (DataViz) · Demand ForecastingSkills:Forecasting · Large Language Models (LLM) · Python · Business Analytics · Business Intelligence (BI) · Artificial Intelligence (AI) · Prompt Engineering · Data Visualization (DataViz) · Demand Forecasting'},\n",
       "  {'company': 'AlderaSoft ',\n",
       "   'position': 'Senior AnalystSenior Analyst',\n",
       "   'workin_period': 'Aug 2022 - Mar 2023 ',\n",
       "   'duration': ' 8 mos',\n",
       "   'description': 'As a System Analyst, I have effectively contributed to various projects including the development of an ETL system, advanced data visualization analytics tools, production calculators, PMS (property management system) for hotels, and applications featuring video content viewing functions.My key responsibilities in these projects included developing a project concept through a conceptual model (BPMN), outlining the main functions of the system (user story) and developing detailed specifications such as use cases, functional and non-functional requirements along with UML diagrams. I was also involved in prototyping using figma and draw.io, and setting tasks for development while continuously monitoring adherence to acceptance criteria.Throughout my work, I have gained proficiency in several crucial tools such as Swagger, Postman, Jira, Confluence, YandexTracker, YandexWiki and more.As a System Analyst, I have effectively contributed to various projects including the development of an ETL system, advanced data visualization analytics tools, production calculators, PMS (property management system) for hotels, and applications featuring video content viewing functions.\\nMy key responsibilities in these projects included developing a project concept through a conceptual model (BPMN), outlining the main functions of the system (user story) and developing detailed specifications such as use cases, functional and non-functional requirements along with UML diagrams. I was also involved in prototyping using figma and draw.io, and setting tasks for development while continuously monitoring adherence to acceptance criteria.\\nThroughout my work, I have gained proficiency in several crucial tools such as Swagger, Postman, Jira, Confluence, YandexTracker, YandexWiki and more.',\n",
       "   'skills': 'N/A'},\n",
       "  {'company': 'Gazpromneft - Vostok ',\n",
       "   'position': 'Petroleum Engineer | Chief Concept EngineerPetroleum Engineer | Chief Concept Engineer',\n",
       "   'workin_period': 'May 2018 - Aug 2022 ',\n",
       "   'duration': ' 4 yrs 4 mos',\n",
       "   'description': \"The key task is the technical and economic assessment of the company's new assets, including: conceptual design, development of asset infrastructure, assessment of capital and operating costs, formation of a financial and economic model, presentation of results on key production and economic indicators.Duties:•\\tConceptual design of development and infrastructure facilities - the conceptual design of one of the licensed blocks allowed to reduce costs by $4 million through the use of an optimal gathering system;•\\tFeasibility study of new (alternative) development options;•\\tCollection of data on forecast production indicators and capital investments of the company in ERA:ISKRA;•\\tAnalysis of changes in forecast indicators (KPI) - developed an Excel macro file using VBA, which allows, taking into account the variability of the initial data, to evaluate the KPI of the project, sensitivity analysis, which reduced the time for preparing similar reports and making decisions by 80%;•\\tCost engineering;•\\tPreparing a presentation report (including presentation to foreign shareholders).The key task is the technical and economic assessment of the company's new assets, including: conceptual design, development of asset infrastructure, assessment of capital and operating costs, formation of a financial and economic model, presentation of results on key production and economic indicators.\\n\\nDuties:\\n•\\tConceptual design of development and infrastructure facilities - the conceptual design of one of the licensed blocks allowed to reduce costs by $4 million through the use of an optimal gathering system;\\n•\\tFeasibility study of new (alternative) development options;\\n•\\tCollection of data on forecast production indicators and capital investments of the company in ERA:ISKRA;\\n•\\tAnalysis of changes in forecast indicators (KPI) - developed an Excel macro file using VBA, which allows, taking into account the variability of the initial data, to evaluate the KPI of the project, sensitivity analysis, which reduced the time for preparing similar reports and making decisions by 80%;\\n•\\tCost engineering;\\n•\\tPreparing a presentation report (including presentation to foreign shareholders).\",\n",
       "   'skills': 'Skills:Financial Modeling · Forecasting · Oil and Gas Engineering · Oil & Gas · Presentation Skills · VBA · Data Visualization (DataViz) · Demand ForecastingSkills:Financial Modeling · Forecasting · Oil and Gas Engineering · Oil & Gas · Presentation Skills · VBA · Data Visualization (DataViz) · Demand Forecasting'},\n",
       "  {'company': 'SSP Software ',\n",
       "   'position': 'Business System AnalystBusiness System Analyst',\n",
       "   'workin_period': 'Jan 2017 - Apr 2018 ',\n",
       "   'duration': ' 1 yr 4 mos',\n",
       "   'description': 'I was engaged in сollection and preparation of analytics for an automated information system for managing field data and production processes in oil, gas and gas condensate fields..Duties:•\\tInteraction with Customers to collect requirements for the system (business trips, conducting face-to-face surveys of work processes and their description, etc.);•\\tDescription and comparative analysis of the results obtained;•\\tFormation of requirements, user scenarios and a unified solution for the functions of the developed System;•\\tElaboration of methods and algorithms of the System functions (calculation of the optimal technological regime, analysis of the Field Development Plan, selection of wells for geological and technical operations, drawing up a research and well workover plan, etc.);•\\tCarrying out the necessary recalculations within the System, taking into account the conducted studies (flow testing, gas condensate studies, field geophysical tests, deep measurements) and PVT studies (EoS, Black Oil);•\\tInteraction with a team of programmers and coordination of the implementation of work stages;•\\tAnalysis of system operation errors and search for their solution;•\\tWriting reports, specifications and component technical specifications;•\\tTesting of the System with subsequent demonstration and thesis defense for the Customer.I was engaged in сollection and preparation of analytics for an automated information system for managing field data and production processes in oil, gas and gas condensate fields..\\n\\nDuties:\\n•\\tInteraction with Customers to collect requirements for the system (business trips, conducting face-to-face surveys of work processes and their description, etc.);\\n•\\tDescription and comparative analysis of the results obtained;\\n•\\tFormation of requirements, user scenarios and a unified solution for the functions of the developed System;\\n•\\tElaboration of methods and algorithms of the System functions (calculation of the optimal technological regime, analysis of the Field Development Plan, selection of wells for geological and technical operations, drawing up a research and well workover plan, etc.);\\n•\\tCarrying out the necessary recalculations within the System, taking into account the conducted studies (flow testing, gas condensate studies, field geophysical tests, deep measurements) and PVT studies (EoS, Black Oil);\\n•\\tInteraction with a team of programmers and coordination of the implementation of work stages;\\n•\\tAnalysis of system operation errors and search for their solution;\\n•\\tWriting reports, specifications and component technical specifications;\\n•\\tTesting of the System with subsequent demonstration and thesis defense for the Customer.',\n",
       "   'skills': 'Skills:Business Analysis · Data Analysis · Oil & Gas · Business Analytics · Demand ForecastingSkills:Business Analysis · Data Analysis · Oil & Gas · Business Analytics · Demand Forecasting'},\n",
       "  {'company': 'Siam-Engineering ',\n",
       "   'position': 'Reservoir EngineerReservoir Engineer',\n",
       "   'workin_period': 'Nov 2012 - Jan 2017 ',\n",
       "   'duration': ' 4 yrs 3 mos',\n",
       "   'description': 'The key task was a comprehensive analysis of the current state of oil field development, identifying candidate wells and the selection of measures to increase oil recovery and stimulate wells.Duties:•\\tAnalysis of the current state of field development, including analysis of the reasons for the decline in oil production, changes in reservoir pressure, determination of the causes of water cut in wells;•\\tIssuance of recommendations for the study and repair of wells;•\\tOptimization of the field development system;•\\tOil depletion analysis;•\\tAnalytical calculations of the effectiveness of geological and technical measures.The key task was a comprehensive analysis of the current state of oil field development, identifying candidate wells and the selection of measures to increase oil recovery and stimulate wells.\\n\\nDuties:\\n•\\tAnalysis of the current state of field development, including analysis of the reasons for the decline in oil production, changes in reservoir pressure, determination of the causes of water cut in wells;\\n•\\tIssuance of recommendations for the study and repair of wells;\\n•\\tOptimization of the field development system;\\n•\\tOil depletion analysis;\\n•\\tAnalytical calculations of the effectiveness of geological and technical measures.',\n",
       "   'skills': 'Skills:Oil and Gas Engineering · Oil & Gas · Presentation Skills · Reservoir Engineering · VBA · Data Visualization (DataViz)Skills:Oil and Gas Engineering · Oil & Gas · Presentation Skills · Reservoir Engineering · VBA · Data Visualization (DataViz)'},\n",
       "  {'company': 'Сибирская Сервисная Компания ',\n",
       "   'position': 'Chief Engineer | Well Completion EngineerChief Engineer | Well Completion Engineer',\n",
       "   'workin_period': 'Jan 2011 - Nov 2012 ',\n",
       "   'duration': ' 1 yr 11 mos',\n",
       "   'description': '•\\tTechnological support for cementing directional, horizontal wells;•\\tTechnological support for cementing sidetracks (liners);•\\tPreparation of documents on the well cementing report;•\\tDrawing up well cementing programs;•\\tProtection of reports to the Customer.•\\tTechnological support for cementing directional, horizontal wells;\\n•\\tTechnological support for cementing sidetracks (liners);\\n•\\tPreparation of documents on the well cementing report;\\n•\\tDrawing up well cementing programs;\\n•\\tProtection of reports to the Customer.',\n",
       "   'skills': 'Skills:Oil & GasSkills:Oil & Gas'},\n",
       "  {'company': 'Imperial Energy ',\n",
       "   'position': 'Field Operator | Oil and Gas Production EngineerField Operator | Oil and Gas Production Engineer',\n",
       "   'workin_period': 'Aug 2009 - Dec 2010 ',\n",
       "   'duration': ' 1 yr 5 mos',\n",
       "   'description': '•\\tMaintenance of the technological process for all methods of oil, gas and gas condensate production;•\\tImplementation of work to maintain the specified operating mode of wells, group metering units and other facilities related to the technology of oil, gas and gas condensate production;•\\tMaintenance of well communications;•\\tEquipment metering.•\\tMaintenance of the technological process for all methods of oil, gas and gas condensate production;\\n•\\tImplementation of work to maintain the specified operating mode of wells, group metering units and other facilities related to the technology of oil, gas and gas condensate production;\\n•\\tMaintenance of well communications;\\n•\\tEquipment metering.',\n",
       "   'skills': 'Skills:Oil and Gas Engineering · Oil & GasSkills:Oil and Gas Engineering · Oil & Gas'}],\n",
       " 'Education': [{'university': 'Heriot-Watt University',\n",
       "   'degree': 'Master of Science (MSc), Petroleum Engineering',\n",
       "   'dates': '2015 - 2016',\n",
       "   'details': ['Activities and societies: Participant of the best Field Development Project (1st place)',\n",
       "    'Graduation thesis: “Uncertainty reduction of drilling wells at the Field A”',\n",
       "    'Skills: Oil and Gas Engineering · Reservoir Engineering · Oil & Gas',\n",
       "    'Diploma'],\n",
       "   'certificates': ['Heriot-Watt University', 'Diploma']},\n",
       "  {'university': 'Peter the Great St.Petersburg Polytechnic University',\n",
       "   'degree': 'Postgraduate Degree, Intelligent Systems',\n",
       "   'dates': 'Feb 2023 - Jun 2023',\n",
       "   'details': ['Grade: A',\n",
       "    'Activities and societies: - High-level Design of Information Control Systems - Project Management - Corporate Information Systems - Intelligent Systems - Software Development Technologies (ML) - Group Project: Safety Helmet Detection expert system - Individual Project: Modelling the system of Permeate neutralisation plant N1',\n",
       "    'A Group Project goal Develop an expert system for recognizing the wearing of safety helmets based on incoming data (photo) that returns a response within an acceptable time frame and with minimal losses. Tasks: - Create use case, swimlane, IDEF0 diagrams - Choose an appropriate architecture - Train a model (Yolo5, CNN) - Create a telegram bot and apply a chosen model Additionally, completed an individual project modeling high-level and low-level design for the Permeate Neutralisation Plant N1 using UML and CodeSys, enhancing skills in system analysis and automation.',\n",
       "    'Skills: Python · Business Analytics',\n",
       "    'Human Machine Interface - Individual Project',\n",
       "    'Application of the models - Group Project',\n",
       "    'Certificate'],\n",
       "   'certificates': ['Peter the Great St.Petersburg Polytechnic University',\n",
       "    'Human Machine Interface - Individual Project',\n",
       "    'Application of the models - Group Project',\n",
       "    'Certificate']},\n",
       "  {'university': 'Tomsk Polytechnic University',\n",
       "   'degree': 'Магистр/ MSc, Разработка нефтяных и газовых месторождений/ Reservoir Engineering',\n",
       "   'dates': '2005 - 2011',\n",
       "   'details': ['Skills: Oil and Gas Engineering · Reservoir Engineering'],\n",
       "   'certificates': ['Tomsk Polytechnic University']}],\n",
       " 'Certification': [{'certification_name': 'Build a Machine Learning Model Skill Path',\n",
       "   'issuer': 'Codecademy',\n",
       "   'issue_date': 'Issued Nov 2024',\n",
       "   'credential_id': 'N/A',\n",
       "   'skills': 'Artificial Intelligence (AI) · Python',\n",
       "   'certificates_or_media': ['Build a Machine Learning Model Skill Path',\n",
       "    'Certificate | Codecademy.pdf',\n",
       "    'Ml_Capstone_Project at GitHub']},\n",
       "  {'certification_name': 'AI Engineering Specialization',\n",
       "   'issuer': 'Scrimba',\n",
       "   'issue_date': 'Issued Mar 2024',\n",
       "   'credential_id': 'Credential ID GANNTUR4L26C',\n",
       "   'skills': 'Large Language Models (LLM) · Artificial Intelligence (AI) · Prompt Engineering',\n",
       "   'certificates_or_media': ['AI Engineering Specialization']},\n",
       "  {'certification_name': 'Supply Chain Analytics Specialization',\n",
       "   'issuer': 'Rutgers University',\n",
       "   'issue_date': 'Issued Jan 2024',\n",
       "   'credential_id': 'Credential ID 4LXCK6T92GYY',\n",
       "   'skills': 'Inventory Analysis · Demand Forecasting · Supply Chain Risk Management · Business Analytics · Forecasting · Supply Chain',\n",
       "   'certificates_or_media': ['Supply Chain Analytics Specialization']},\n",
       "  {'certification_name': 'IBM Data Analyst Specialization',\n",
       "   'issuer': 'IBM',\n",
       "   'issue_date': 'Issued Sep 2022',\n",
       "   'credential_id': 'Credential ID 68VUENLDVVJ5',\n",
       "   'skills': 'Python · Data Visualization (DataViz) · Microsoft Excel · Python Programming · Business Intelligence (BI) · Data Analysis · SQL',\n",
       "   'certificates_or_media': ['IBM Data Analyst Specialization']},\n",
       "  {'certification_name': 'Google Project Management: Specialization',\n",
       "   'issuer': 'Google',\n",
       "   'issue_date': 'Issued May 2022',\n",
       "   'credential_id': 'Credential ID EQDFTKPMCPVT',\n",
       "   'skills': 'Lean Six Sigma',\n",
       "   'certificates_or_media': ['Google Project Management: Specialization']}],\n",
       " 'Posts': [{'Дата': '6d •6 days ago',\n",
       "   'Автор': 'Egor ZubenkoEgor Zubenko',\n",
       "   'Контент': 'Build a Machine Learning Model Skill Path fromCodecademy!So, it was useful to refresh my knowledge of regression, classification, and working with PyTorch and scikit-learn.',\n",
       "   'Реакции': '9Maksim Stepura and 8 others',\n",
       "   'Комментарии': '1 comment',\n",
       "   'Репосты': '0',\n",
       "   'Впечатления': 'N/A'},\n",
       "  {'Дата': '1mo •1 month ago',\n",
       "   'Автор': 'Egor ZubenkoEgor Zubenko',\n",
       "   'Контент': 'It really sounds interesting ))\"\"\"Based on our interactions, it seems you have a strong interest in data analysis, AI systems, cryptography, and project management. A career path you might enjoy, which perhaps hasn’t crossed your mind, could be **AI Product Manager or AI Solutions Architect**.Here’s why:1. **AI Product Manager**: You already work with advanced analytics, machine learning, and agent-based systems like LangGraph and CrewAI. This role would allow you to combine your deep understanding of data, product development, and market trends. You’d focus on developing AI-driven products that optimize workflows, which aligns well with your interest in call center automation and optimizing operator efficiency.2. **AI Solutions Architect**: This position would involve designing and implementing AI systems tailored to specific business needs. Given your experience with automation projects, especially in logistics and call centers, you’d excel in crafting custom AI models that solve practical problems in CPA marketing or supplement production logistics.Both of these roles combine your technical expertise with strategic planning, and they allow you to leverage your knowledge of emerging technologies, particularly in AI and blockchain, to drive innovation within businesses.Does this path spark any new interest or ideas for you?\"\"\"…more',\n",
       "   'Реакции': '2Maksim Stepura and 1 other',\n",
       "   'Комментарии': '1 comment',\n",
       "   'Репосты': '0',\n",
       "   'Впечатления': 'N/A'},\n",
       "  {'Дата': '8mo •9 months ago',\n",
       "   'Автор': 'Egor ZubenkoEgor Zubenko',\n",
       "   'Контент': 'I’m happy to share that I’ve obtained the AI Engineering course fromScrimbaand highly (!) recommend it.It gives not only theoretical knowledge but also practical skills in AI application development. The instructors and course materials are top! This course is beneficial for anyone looking to dive deeper into AI.P.S. I also had to start learning JavaScript from scratch to fully engage with the course content )))hashtag#LLMhashtag#AIEngineeringhashtag#ArtificialIntelligence…more',\n",
       "   'Реакции': '9',\n",
       "   'Комментарии': '6 comments',\n",
       "   'Репосты': '0',\n",
       "   'Впечатления': 'N/A'},\n",
       "  {'Дата': '8mo •9 months ago',\n",
       "   'Автор': 'Egor ZubenkoEgor Zubenko',\n",
       "   'Контент': 'Hello!While working on a new feature of the system, I encountered a problem that I do not yet understand how to solve.So, there is a database that will be regularly updated and expanded with new content. Vectors are created using OpenAI tools (embedding), they are then saved in the database along with functionality for searching for similar vectors.❓The question itself is: How can we effectively maintain the relevance of these vectors, minimizing the need for their constant recalculation when changes are made to the content? Is it possible to use metadata, for example, by adding a timestamp to it?The structure of the table in the database is as follows:- id: a unique document identifier.- content: textual content of the document (in my case - chunk).- metadata: document metadata in JSONB format.- embedding: vector representation of the document with a dimension of 1536.…more',\n",
       "   'Реакции': '2',\n",
       "   'Комментарии': '0',\n",
       "   'Репосты': '0',\n",
       "   'Впечатления': 'N/A'},\n",
       "  {'Дата': '1yr •1 year ago',\n",
       "   'Автор': 'Egor ZubenkoEgor Zubenko',\n",
       "   'Контент': \"🎓 Excited to announce that I've completed the Supply Chain Management Specialization byCourseraandRutgers Universityof New Jersey! 🚀 Studying onCourseraoffered a cool opportunity to expand skills while diving deeper into industries I work with. Looking forward to implementing this new knowledge in developing SCM systems!hashtag#SupplyChainManagementhashtag#LifelongLearnerhashtag#Courserahashtag#RutgersUniversity…more\",\n",
       "   'Реакции': '14',\n",
       "   'Комментарии': '2 comments',\n",
       "   'Репосты': '0',\n",
       "   'Впечатления': 'N/A'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#********** CHECK THE RESULT *************\n",
    "\n",
    "profile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d4a9770-3222-4a39-aca6-6de939f892c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закрываем драйвер\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9553d847-720a-4c11-8f41-a80a56c7bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"profile_data.json\"\n",
    "\n",
    "\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(profile_data, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7f741e-e785-4ef9-9195-e584a5f97eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
