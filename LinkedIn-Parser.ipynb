{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aaf5078-9e44-40a5-99a9-a3d7a802dc11",
   "metadata": {},
   "source": [
    "### Connection to LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9e13de-c61b-4e1d-96e3-26a606db29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb11c510-8789-4ad8-8274-73b65efc8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6964268b-c983-481d-83ec-442e0a6c6c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–í—Ö–æ–¥ –≤ LinkedIn, –≤–æ–π—Ç–∏ | LinkedIn'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.linkedin.com/login')\n",
    "time.sleep(2)\n",
    "driver.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3013317-0892-4fa0-942d-9e4d06919dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** LOG IN *************\n",
    "\n",
    "email = driver.find_element(By.ID, 'username')\n",
    "password = driver.find_element(By.ID, 'password')\n",
    "\n",
    "email.send_keys(os.environ['LINKEDIN_EMAIL'])\n",
    "password.send_keys(os.environ['LINKEDIN_PASSWORD'])\n",
    "\n",
    "password.submit()\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4db4b09-85bc-4cb7-b42d-724b637cddd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1) Egor Zubenko | LinkedIn'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#********** GO TO PROFILE *************\n",
    "url = \"https://www.linkedin.com/in/zubenkoey/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "driver.title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbbe440-56a7-4d73-955b-117a11d63810",
   "metadata": {},
   "source": [
    "### Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e207a-729c-4944-bdd0-d118d0131b55",
   "metadata": {},
   "source": [
    "#### Name and Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1dbb79-5eb4-4ea8-986f-e5551f084d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Egor Zubenko',\n",
       " 'url': 'https://www.linkedin.com/in/zubenkoey/',\n",
       " 'headline': 'Business System Analyst @ Webvork | Python, SQL, OpenAI'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_data = {}\n",
    "\n",
    "#********** GET NAME *************\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "name = soup.find('h1', {'class': 'REcVsMzJIjWGrvfwbuhgiUDStqsxZjeKqIQFB inline t-24 v-align-middle break-words'}).get_text()\n",
    "\n",
    "#********** GET HEADLINE *************\n",
    "headline = soup.find('div', {'class': 'text-body-medium break-words'})\n",
    "headline = headline.get_text().strip()\n",
    "\n",
    "profile_data['name'] = name\n",
    "profile_data['url'] = url\n",
    "profile_data['headline'] = headline\n",
    "\n",
    "profile_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca13d931-15b7-4f62-99ab-88d30fa94111",
   "metadata": {},
   "source": [
    "#### About"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0b9db1-b2a4-47a1-bebc-1e048b103612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Egor Zubenko',\n",
       " 'url': 'https://www.linkedin.com/in/zubenkoey/',\n",
       " 'headline': 'Business System Analyst @ Webvork | Python, SQL, OpenAI',\n",
       " 'About': \"I'm an Analyst with a strong background in the upstream sector of Oil&Gas industry as a Petroleum Engineer, and Business Analysis for IT projects. Currently, I am involved in various IT projects, such as conducting a comprehensive CRM system analysis, proposing a new algorithm for assigning orders to call center operators, and describing a system feature that enables data-driven decision making. I would like to move on and develop in the field of business and data analysis, implement AI solutions and develop IT products.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#********** GET ABOUT INFO *************\n",
    "\n",
    "xPath = '//*[@id=\"profile-content\"]/div/div[2]/div/div/main/section[4]/div[3]/div/div/div/span[1]'\n",
    "\n",
    "try:\n",
    "    # Locate the element\n",
    "    element = driver.find_element(By.XPATH, xPath)\n",
    "    text = element.text\n",
    "    profile_data['About'] = text\n",
    "except Exception as e:\n",
    "    print(\"Error finding the About section:\", e)\n",
    "\n",
    "profile_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9786cdd-15ab-4115-8c7b-3d94298f2348",
   "metadata": {},
   "source": [
    "#### Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c556f089-536b-4535-9605-85b3021c6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** GO TO EXPERIENCE PAGE *************\n",
    "\n",
    "driver.get('https://www.linkedin.com/in/zubenkoey/details/experience/')\n",
    "time.sleep(2)\n",
    "\n",
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6baf8a6a-6ee7-4678-83c8-b02d26f5590d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#********** EXTRACT EXPERIENCE *************\n",
    "\n",
    "# –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ page_source —Å–æ–¥–µ—Ä–∂–∏—Ç HTML-–∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "# –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å–µ–∫—Ü–∏–∏ –æ–ø—ã—Ç–∞\n",
    "sections = soup.find_all('li', class_='pvs-list__paged-list-item')\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "experience_data = []\n",
    "\n",
    "# –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Å–µ–∫—Ü–∏—è–º –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "for sec in sections:\n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏\n",
    "    company_tag = sec.find('span', class_='t-14 t-normal')\n",
    "    company_name = company_tag.get_text(strip=True).split('¬∑')[0] if company_tag else 'N/A'\n",
    "    \n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–ª–∂–Ω–æ—Å—Ç—å\n",
    "    position_tag = sec.find('div', class_='display-flex align-items-center mr1 t-bold')\n",
    "    position_name = position_tag.get_text(strip=True).split('¬∑')[0] if position_tag else 'N/A'\n",
    "\n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–ª–∂–Ω–æ—Å—Ç—å\n",
    "    working_period_tag = sec.find('span', class_='pvs-entity__caption-wrapper')\n",
    "    working_period = working_period_tag.get_text(strip=True).split('¬∑')[0] if working_period_tag else 'N/A'\n",
    "\n",
    "    # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "    duration_tag = sec.find('span', class_='pvs-entity__caption-wrapper')\n",
    "    duration = duration_tag.get_text(strip=True).split('¬∑')[1] if duration_tag else 'N/A'\n",
    "\n",
    "    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤–Ω—É—Ç—Ä–∏ ul/li\n",
    "    list_items = sec.find_all('li', class_='pvs-list__item--with-top-padding')\n",
    "    \n",
    "    # Description\n",
    "    description = list_items[0].get_text(strip=True) if len(list_items) > 0 else 'N/A'\n",
    "\n",
    "    # Skills\n",
    "    skills = list_items[1].get_text(strip=True) if len(list_items) > 1 else 'N/A'\n",
    "\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–ø–∏—Å–æ–∫\n",
    "    experience_data.append({\n",
    "        'company': company_name,\n",
    "        'position': position_name,\n",
    "        'workin_period': working_period,\n",
    "        'duration': duration,\n",
    "        'description': description,\n",
    "        'skills': skills,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1829ce8-ab63-4fd4-8120-f359a4872f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data['Experience'] = experience_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37788a6-a034-42b0-96d4-a32763169989",
   "metadata": {},
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3643f2aa-f6d5-4262-808d-f0c8e7ab1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** GO TO EDUCATION PAGE *************\n",
    "\n",
    "driver.get('https://www.linkedin.com/in/zubenkoey/details/education/')\n",
    "time.sleep(2)\n",
    "\n",
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51fa5ae7-1994-43de-9be9-25f0a91087d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University: Heriot-Watt University\n",
      "Degree: Master of Science (MSc), Petroleum Engineering\n",
      "Dates: 2015 - 2016\n",
      "Details:\n",
      "  - Activities and societies: Participant of the best Field Development Project (1st place)\n",
      "  - Graduation thesis: ‚ÄúUncertainty reduction of drilling wells at the Field A‚Äù\n",
      "  - Skills: Oil and Gas Engineering ¬∑ Reservoir Engineering ¬∑ Oil & Gas\n",
      "  - Diploma\n",
      "Certificates/Media:\n",
      "  - Heriot-Watt University\n",
      "  - Diploma\n",
      "\n",
      "\n",
      "University: Peter the Great St.Petersburg Polytechnic University\n",
      "Degree: Postgraduate Degree, Intelligent Systems\n",
      "Dates: Feb 2023 - Jun 2023\n",
      "Details:\n",
      "  - Grade: A\n",
      "  - Activities and societies: - High-level Design of Information Control Systems - Project Management - Corporate Information Systems - Intelligent Systems - Software Development Technologies (ML) - Group Project: Safety Helmet Detection expert system - Individual Project: Modelling the system of Permeate neutralisation plant N1\n",
      "  - A Group Project goal Develop an expert system for recognizing the wearing of safety helmets based on incoming data (photo) that returns a response within an acceptable time frame and with minimal losses. Tasks: - Create use case, swimlane, IDEF0 diagrams - Choose an appropriate architecture - Train a model (Yolo5, CNN) - Create a telegram bot and apply a chosen model Additionally, completed an individual project modeling high-level and low-level design for the Permeate Neutralisation Plant N1 using UML and CodeSys, enhancing skills in system analysis and automation.\n",
      "  - Skills: Python ¬∑ Business Analytics\n",
      "  - Human Machine Interface - Individual Project\n",
      "  - Application of the models - Group Project\n",
      "  - Certificate\n",
      "Certificates/Media:\n",
      "  - Peter the Great St.Petersburg Polytechnic University\n",
      "  - Human Machine Interface - Individual Project\n",
      "  - Application of the models - Group Project\n",
      "  - Certificate\n",
      "\n",
      "\n",
      "University: Tomsk Polytechnic University\n",
      "Degree: –ú–∞–≥–∏—Å—Ç—Ä/ MSc, –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Ñ—Ç—è–Ω—ã—Ö –∏ –≥–∞–∑–æ–≤—ã—Ö –º–µ—Å—Ç–æ—Ä–æ–∂–¥–µ–Ω–∏–π/ Reservoir Engineering\n",
      "Dates: 2005 - 2011\n",
      "Details:\n",
      "  - Skills: Oil and Gas Engineering ¬∑ Reservoir Engineering\n",
      "Certificates/Media:\n",
      "  - Tomsk Polytechnic University\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#********** EXTRACT EDUCATION *************\n",
    "\n",
    "# –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ html_data —Å–æ–¥–µ—Ä–∂–∏—Ç HTML-–∫–æ–¥ —Å–µ–∫—Ü–∏–∏ Education\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "# –ù–∞—Ö–æ–¥–∏–º —Å–µ–∫—Ü–∏—é Education\n",
    "education_section = soup.find('div', class_='pvs-list__container')\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "education_data = []\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞–π–¥–µ–Ω–∞ –ª–∏ —Å–µ–∫—Ü–∏—è Education\n",
    "if education_section:\n",
    "    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
    "    education_items = education_section.find_all('li', class_='pvs-list__paged-list-item')\n",
    "    \n",
    "    for item in education_items:\n",
    "        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞\n",
    "        university_tag = item.find('div', class_='display-flex align-items-center mr1 hoverable-link-text t-bold')\n",
    "        university = 'N/A'\n",
    "        if university_tag:\n",
    "            span = university_tag.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                university = span.get_text(strip=True)\n",
    "        \n",
    "        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç–µ–ø–µ–Ω–∏ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è\n",
    "        degree_tag = item.find('span', class_='t-14 t-normal')\n",
    "        degree = 'N/A'\n",
    "        if degree_tag:\n",
    "            span = degree_tag.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                degree = span.get_text(strip=True)\n",
    "        \n",
    "        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç –æ–±—É—á–µ–Ω–∏—è\n",
    "        dates_tag = item.find('span', class_='t-14 t-normal t-black--light')\n",
    "        dates = 'N/A'\n",
    "        if dates_tag:\n",
    "            span = dates_tag.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                dates = span.get_text(strip=True)\n",
    "        \n",
    "        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –∏ –ø—Ä–æ–µ–∫—Ç–æ–≤\n",
    "        details = []\n",
    "        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã li –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—É—â–µ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
    "        detail_items = item.find_all('li', class_='OxttavmlcaTTQyNiTiLxfszAmvmHtRgbWzWcY')\n",
    "        for detail in detail_items:\n",
    "            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π span —Å aria-hidden=true\n",
    "            span = detail.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                text = span.get_text(separator=' ', strip=True)\n",
    "                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–µ –ø—É—Å—Ç–æ–π –∏ –Ω–µ –¥—É–±–ª–∏—Ä—É–µ—Ç—Å—è\n",
    "                if text and text not in details:\n",
    "                    details.append(text)\n",
    "        \n",
    "        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤ –∏–ª–∏ –º–µ–¥–∏–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "        certificates = []\n",
    "        # –í–Ω—É—Ç—Ä–∏ item, –∏—â–µ–º –≤—Å–µ 'a' —Å class='optional-action-target-wrapper', –Ω–æ –∏—Å–∫–ª—é—á–∞–µ–º 'edit' –∏ 'view reorder'\n",
    "        media_links = item.find_all('a', class_='optional-action-target-wrapper')\n",
    "        for media in media_links:\n",
    "            aria_label = media.get('aria-label', '').lower()\n",
    "            if 'edit education' in aria_label or 'view education reorder screen' in aria_label:\n",
    "                continue  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É\n",
    "            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ span —Å aria-hidden=true –≤–Ω—É—Ç—Ä–∏ 'a'\n",
    "            span = media.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                media_text = span.get_text(strip=True)\n",
    "                if media_text and media_text not in certificates:\n",
    "                    certificates.append(media_text)\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "        education_data.append({\n",
    "            'university': university,\n",
    "            'degree': degree,\n",
    "            'dates': dates,\n",
    "            'details': details,\n",
    "            'certificates': certificates\n",
    "        })\n",
    "\n",
    "# –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "for edu in education_data:\n",
    "    print(f\"University: {edu['university']}\")\n",
    "    print(f\"Degree: {edu['degree']}\")\n",
    "    print(f\"Dates: {edu['dates']}\")\n",
    "    print(\"Details:\")\n",
    "    for detail in edu['details']:\n",
    "        print(f\"  - {detail}\")\n",
    "    if edu['certificates']:\n",
    "        print(\"Certificates/Media:\")\n",
    "        for cert in edu['certificates']:\n",
    "            print(f\"  - {cert}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21e671a6-df76-4b46-8f74-12569f155c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data['Education'] = education_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c750619-2835-4fa1-b6e3-a2218f7b96a5",
   "metadata": {},
   "source": [
    "#### Licenses & certifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4876750-cc35-4646-8ffb-971eb341fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** GO TO Licenses & certifications PAGE *************\n",
    "\n",
    "driver.get('https://www.linkedin.com/in/zubenkoey/details/certifications/')\n",
    "time.sleep(2)\n",
    "\n",
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00e2bb21-6c27-43fc-b08c-c6e3c0e77547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** CHECK THE Licenses & certifications PAGE *************\n",
    "\n",
    "# soup = BeautifulSoup(page_source, 'lxml')\n",
    "# sections = soup.find_all('div', {'class': 'scaffold-finite-scroll__content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8909833-2c31-415b-85bf-7e5daccff09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'certification_name': 'Build a Machine Learning Model Skill Path', 'issuer': 'Codecademy', 'issue_date': 'Issued Nov 2024', 'credential_id': 'N/A', 'skills': 'Artificial Intelligence (AI) ¬∑ Python', 'certificates_or_media': ['Build a Machine Learning Model Skill Path', 'Certificate | Codecademy.pdf', 'Ml_Capstone_Project at GitHub']}\n",
      "{'certification_name': 'AI Engineering Specialization', 'issuer': 'Scrimba', 'issue_date': 'Issued Mar 2024', 'credential_id': 'Credential ID GANNTUR4L26C', 'skills': 'Large Language Models (LLM) ¬∑ Artificial Intelligence (AI) ¬∑ Prompt Engineering', 'certificates_or_media': ['AI Engineering Specialization']}\n",
      "{'certification_name': 'Supply Chain Analytics Specialization', 'issuer': 'Rutgers University', 'issue_date': 'Issued Jan 2024', 'credential_id': 'Credential ID 4LXCK6T92GYY', 'skills': 'Inventory Analysis ¬∑ Demand Forecasting ¬∑ Supply Chain Risk Management ¬∑ Business Analytics ¬∑ Forecasting ¬∑ Supply Chain', 'certificates_or_media': ['Supply Chain Analytics Specialization']}\n",
      "{'certification_name': 'IBM Data Analyst Specialization', 'issuer': 'IBM', 'issue_date': 'Issued Sep 2022', 'credential_id': 'Credential ID 68VUENLDVVJ5', 'skills': 'Python ¬∑ Data Visualization (DataViz) ¬∑ Microsoft Excel ¬∑ Python Programming ¬∑ Business Intelligence (BI) ¬∑ Data Analysis ¬∑ SQL', 'certificates_or_media': ['IBM Data Analyst Specialization']}\n",
      "{'certification_name': 'Google Project Management: Specialization', 'issuer': 'Google', 'issue_date': 'Issued May 2022', 'credential_id': 'Credential ID EQDFTKPMCPVT', 'skills': 'Lean Six Sigma', 'certificates_or_media': ['Google Project Management: Specialization']}\n"
     ]
    }
   ],
   "source": [
    "#********** EXTRACT Licenses & certifications *************\n",
    "\n",
    "# –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ page_source —Å–æ–¥–µ—Ä–∂–∏—Ç HTML-–∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞–º–∏\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "# –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å–µ–∫—Ü–∏–∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤\n",
    "sections = soup.find_all('div', {'class': 'scaffold-finite-scroll__content'})\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞—Ö\n",
    "certification_data = []\n",
    "\n",
    "# –ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –∫–∞–∂–¥–æ–π —Å–µ–∫—Ü–∏–∏\n",
    "for section in sections:\n",
    "    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏ —Å–µ–∫—Ü–∏–∏\n",
    "    certification_items = section.find_all('li', class_='pvs-list__paged-list-item')\n",
    "    \n",
    "    for item in certification_items:\n",
    "        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞\n",
    "        name_tag = item.find('div', class_='display-flex align-items-center mr1 hoverable-link-text t-bold')\n",
    "        certification_name = 'N/A'\n",
    "        if name_tag:\n",
    "            span = name_tag.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                certification_name = span.get_text(strip=True)\n",
    "        \n",
    "        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–¥–∞—Ç–µ–ª—è (issuer)\n",
    "        issuer_tag = item.find('span', class_='t-14 t-normal')\n",
    "        issuer = 'N/A'\n",
    "        if issuer_tag:\n",
    "            span = issuer_tag.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                issuer = span.get_text(strip=True)\n",
    "        \n",
    "        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç—ã –≤—ã–¥–∞—á–∏\n",
    "        date_tag = item.find('span', class_='t-14 t-normal t-black--light')\n",
    "        issue_date = 'N/A'\n",
    "        if date_tag:\n",
    "            span = date_tag.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                issue_date = span.get_text(strip=True)\n",
    "        \n",
    "        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ Credential ID\n",
    "        credential_id_tag = item.find_all('span', class_='t-14 t-normal t-black--light')\n",
    "        credential_id = 'N/A'\n",
    "        if len(credential_id_tag) >= 2:\n",
    "            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ Credential ID –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–æ –≤—Ç–æ—Ä–æ–º span\n",
    "            span = credential_id_tag[1].find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                credential_id = span.get_text(strip=True)\n",
    "        \n",
    "        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ (Skills)\n",
    "        skills = 'N/A'\n",
    "        skills_container = item.find('div', class_='display-flex align-items-center t-14 t-normal t-black')\n",
    "        if skills_container:\n",
    "            skills_span = skills_container.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if skills_span:\n",
    "                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ \"Skills:\"\n",
    "                skills_text = skills_span.get_text(strip=True)\n",
    "                if 'Skills:' in skills_text:\n",
    "                    skills = skills_text.replace('Skills:', '').strip()\n",
    "        \n",
    "        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤ –∏–ª–∏ –º–µ–¥–∏–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "        certificates = []\n",
    "        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ 'a' —Ç–µ–≥–∏ —Å –∫–ª–∞—Å—Å–æ–º 'optional-action-target-wrapper' –≤–Ω—É—Ç—Ä–∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞\n",
    "        media_links = item.find_all('a', class_='optional-action-target-wrapper')\n",
    "        for media in media_links:\n",
    "            # –ò–∑–±–µ–≥–∞–µ–º —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–ª–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏\n",
    "            aria_label = media.get('aria-label', '').lower()\n",
    "            if 'edit certification' in aria_label or 'show credential' in aria_label:\n",
    "                continue  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø—Ä–æ—Å–º–æ—Ç—Ä\n",
    "            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ span —Å aria-hidden=\"true\"\n",
    "            span = media.find('span', attrs={'aria-hidden': 'true'})\n",
    "            if span:\n",
    "                media_text = span.get_text(strip=True)\n",
    "                if media_text and media_text not in certificates:\n",
    "                    certificates.append(media_text)\n",
    "        \n",
    "        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, Skills)\n",
    "        # –í –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ —É–∂–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã –Ω–∞–≤—ã–∫–∏, –Ω–æ –µ—Å–ª–∏ –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –¥–µ—Ç–∞–ª–∏, –º–æ–∂–Ω–æ –∏—Ö –¥–æ–±–∞–≤–∏—Ç—å\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–µ\n",
    "        certification_data.append({\n",
    "            'certification_name': certification_name,\n",
    "            'issuer': issuer,\n",
    "            'issue_date': issue_date,\n",
    "            'credential_id': credential_id,\n",
    "            'skills': skills,\n",
    "            'certificates_or_media': certificates\n",
    "        })\n",
    "\n",
    "# –í—ã–≤–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "for cert in certification_data:\n",
    "    print(cert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8779a07-58d5-457a-9460-08b63e347946",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data['Certification'] = certification_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8cf8b-7c4c-4d3c-b080-1014ed8dd333",
   "metadata": {},
   "source": [
    "#### Social MEdia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "416bfef6-a177-4285-9fe8-9014b369fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** GO TO MEDIA PAGE *************\n",
    "\n",
    "driver.get('https://www.linkedin.com/in/zubenkoey/recent-activity/all/')\n",
    "time.sleep(2)\n",
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edd2a056-0c12-4ade-8699-9f3f788b2228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'–î–∞—Ç–∞': '6d ‚Ä¢6 days ago',\n",
       "  '–ê–≤—Ç–æ—Ä': 'Egor ZubenkoEgor Zubenko',\n",
       "  '–ö–æ–Ω—Ç–µ–Ω—Ç': 'Build a Machine Learning Model Skill Path fromCodecademy!So, it was useful to refresh my knowledge of regression, classification, and working with PyTorch and scikit-learn.',\n",
       "  '–†–µ–∞–∫—Ü–∏–∏': '9Maksim Stepura and 8 others',\n",
       "  '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': '1 comment',\n",
       "  '–†–µ–ø–æ—Å—Ç—ã': '0',\n",
       "  '–í–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è': 'N/A'},\n",
       " {'–î–∞—Ç–∞': '1mo ‚Ä¢1 month ago',\n",
       "  '–ê–≤—Ç–æ—Ä': 'Egor ZubenkoEgor Zubenko',\n",
       "  '–ö–æ–Ω—Ç–µ–Ω—Ç': 'It really sounds interesting ))\"\"\"Based on our interactions, it seems you have a strong interest in data analysis, AI systems, cryptography, and project management. A career path you might enjoy, which perhaps hasn‚Äôt crossed your mind, could be **AI Product Manager or AI Solutions Architect**.Here‚Äôs why:1. **AI Product Manager**: You already work with advanced analytics, machine learning, and agent-based systems like LangGraph and CrewAI. This role would allow you to combine your deep understanding of data, product development, and market trends. You‚Äôd focus on developing AI-driven products that optimize workflows, which aligns well with your interest in call center automation and optimizing operator efficiency.2. **AI Solutions Architect**: This position would involve designing and implementing AI systems tailored to specific business needs. Given your experience with automation projects, especially in logistics and call centers, you‚Äôd excel in crafting custom AI models that solve practical problems in CPA marketing or supplement production logistics.Both of these roles combine your technical expertise with strategic planning, and they allow you to leverage your knowledge of emerging technologies, particularly in AI and blockchain, to drive innovation within businesses.Does this path spark any new interest or ideas for you?\"\"\"‚Ä¶more',\n",
       "  '–†–µ–∞–∫—Ü–∏–∏': '2Maksim Stepura and 1 other',\n",
       "  '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': '1 comment',\n",
       "  '–†–µ–ø–æ—Å—Ç—ã': '0',\n",
       "  '–í–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è': 'N/A'},\n",
       " {'–î–∞—Ç–∞': '8mo ‚Ä¢9 months ago',\n",
       "  '–ê–≤—Ç–æ—Ä': 'Egor ZubenkoEgor Zubenko',\n",
       "  '–ö–æ–Ω—Ç–µ–Ω—Ç': 'I‚Äôm happy to share that I‚Äôve obtained the AI Engineering course fromScrimbaand highly (!) recommend it.It gives not only theoretical knowledge but also practical skills in AI application development. The instructors and course materials are top! This course is beneficial for anyone looking to dive deeper into AI.P.S. I also had to start learning JavaScript from scratch to fully engage with the course content )))hashtag#LLMhashtag#AIEngineeringhashtag#ArtificialIntelligence‚Ä¶more',\n",
       "  '–†–µ–∞–∫—Ü–∏–∏': '9',\n",
       "  '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': '6 comments',\n",
       "  '–†–µ–ø–æ—Å—Ç—ã': '0',\n",
       "  '–í–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è': 'N/A'},\n",
       " {'–î–∞—Ç–∞': '8mo ‚Ä¢9 months ago',\n",
       "  '–ê–≤—Ç–æ—Ä': 'Egor ZubenkoEgor Zubenko',\n",
       "  '–ö–æ–Ω—Ç–µ–Ω—Ç': 'Hello!While working on a new feature of the system, I encountered a problem that I do not yet understand how to solve.So, there is a database that will be regularly updated and expanded with new content. Vectors are created using OpenAI tools (embedding), they are then saved in the database along with functionality for searching for similar vectors.‚ùìThe question itself is: How can we effectively maintain the relevance of these vectors, minimizing the need for their constant recalculation when changes are made to the content? Is it possible to use metadata, for example, by adding a timestamp to it?The structure of the table in the database is as follows:- id: a unique document identifier.- content: textual content of the document (in my case - chunk).- metadata: document metadata in JSONB format.- embedding: vector representation of the document with a dimension of 1536.‚Ä¶more',\n",
       "  '–†–µ–∞–∫—Ü–∏–∏': '2',\n",
       "  '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': '0',\n",
       "  '–†–µ–ø–æ—Å—Ç—ã': '0',\n",
       "  '–í–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è': 'N/A'},\n",
       " {'–î–∞—Ç–∞': '1yr ‚Ä¢1 year ago',\n",
       "  '–ê–≤—Ç–æ—Ä': 'Egor ZubenkoEgor Zubenko',\n",
       "  '–ö–æ–Ω—Ç–µ–Ω—Ç': \"üéì Excited to announce that I've completed the Supply Chain Management Specialization byCourseraandRutgers Universityof New Jersey! üöÄ Studying onCourseraoffered a cool opportunity to expand skills while diving deeper into industries I work with. Looking forward to implementing this new knowledge in developing SCM systems!hashtag#SupplyChainManagementhashtag#LifelongLearnerhashtag#Courserahashtag#RutgersUniversity‚Ä¶more\",\n",
       "  '–†–µ–∞–∫—Ü–∏–∏': '14',\n",
       "  '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': '2 comments',\n",
       "  '–†–µ–ø–æ—Å—Ç—ã': '0',\n",
       "  '–í–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è': 'N/A'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#********** EXTRACT MEDIAs *************\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "# –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –≤—Å–µ—Ö –ø–æ—Å—Ç–æ–≤\n",
    "sections = soup.find('div', {'class': 'scaffold-finite-scroll__content'})\n",
    "posts = sections.find_all('li', {'class': 'uZTLYReyXHzCftLccdpNxgzddhEgFKMTEnQ'})\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "data = []\n",
    "\n",
    "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç–∞\n",
    "for post in posts:\n",
    "    try:\n",
    "        # –î–∞—Ç–∞\n",
    "        date_element = post.find('a', {'class': 'update-components-actor__sub-description-link'})\n",
    "        date = date_element.get_text(strip=True) if date_element else None\n",
    "        \n",
    "        # –ê–≤—Ç–æ—Ä\n",
    "        author_element = post.find('span', {'class': 'NyBDmOsEjERFePrZbwKjouqNUZEwPnWBI'})\n",
    "        author = author_element.get_text(strip=True) if author_element else None\n",
    "        \n",
    "        # –ö–æ–Ω—Ç–µ–Ω—Ç\n",
    "        content_element = post.find('div', {'class': 'feed-shared-inline-show-more-text'})\n",
    "        content = content_element.get_text(strip=True) if content_element else None\n",
    "        \n",
    "        # –†–µ–∞–∫—Ü–∏–∏\n",
    "        reactions_element = post.find('li', {'class': 'social-details-social-counts__reactions'})\n",
    "        reactions = reactions_element.get_text(strip=True) if reactions_element else None\n",
    "        \n",
    "        # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏\n",
    "        comments_element = post.find('li', {'class': 'social-details-social-counts__comments'})\n",
    "        comments = comments_element.get_text(strip=True) if comments_element else None\n",
    "        \n",
    "        # –†–µ–ø–æ—Å—Ç—ã (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)\n",
    "        reposts_element = post.find('button', {'aria-label': 'Repost'})\n",
    "        reposts = reposts_element.get_text(strip=True) if reposts_element else \"0\"\n",
    "        \n",
    "        # –í–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å –∞–Ω–∞–ª–∏—Ç–∏–∫–∞)\n",
    "        impressions_element = post.find('strong', {'class': 'ca-entry-point__num-views'})\n",
    "        impressions = impressions_element.get_text(strip=True) if impressions_element else None\n",
    "\n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –ø–æ—Å—Ç—ã, –≥–¥–µ –¥–∞—Ç–∞, –∞–≤—Ç–æ—Ä –∏ –∫–æ–Ω—Ç–µ–Ω—Ç —Å—É—â–µ—Å—Ç–≤—É—é—Ç\n",
    "        if date and author and content:\n",
    "            data.append({\n",
    "                '–î–∞—Ç–∞': date,\n",
    "                '–ê–≤—Ç–æ—Ä': author,\n",
    "                '–ö–æ–Ω—Ç–µ–Ω—Ç': content,\n",
    "                '–†–µ–∞–∫—Ü–∏–∏': reactions or \"0\",\n",
    "                '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': comments or \"0\",\n",
    "                '–†–µ–ø–æ—Å—Ç—ã': reposts,\n",
    "                '–í–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è': impressions or \"N/A\"\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞: {e}\")\n",
    "\n",
    "# –í—ã–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad5ab4cc-e519-4d60-9d0b-a235f2cfd25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data['Posts'] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dcb4dc-d4ba-4cb8-aab4-ff5bfcdca4f3",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae5fe52a-1b21-476f-ac5e-96fc760d3f19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Egor Zubenko',\n",
       " 'url': 'https://www.linkedin.com/in/zubenkoey/',\n",
       " 'headline': 'Business System Analyst @ Webvork | Python, SQL, OpenAI',\n",
       " 'About': \"I'm an Analyst with a strong background in the upstream sector of Oil&Gas industry as a Petroleum Engineer, and Business Analysis for IT projects. Currently, I am involved in various IT projects, such as conducting a comprehensive CRM system analysis, proposing a new algorithm for assigning orders to call center operators, and describing a system feature that enables data-driven decision making. I would like to move on and develop in the field of business and data analysis, implement AI solutions and develop IT products.\",\n",
       " 'Experience': [{'company': 'Webvork ',\n",
       "   'position': 'Business System AnalystBusiness System Analyst',\n",
       "   'workin_period': 'Apr 2023 - Present ',\n",
       "   'duration': ' 1 yr 9 mos',\n",
       "   'description': \"As a Business Analyst and Data Specialist, I've leveraged my expertise in Python, SQL, and OpenAI's API to drive company profitability through meticulous data analysis and process optimization.Here's a snapshot of my core accomplishments:- Conducted a comprehensive CRM system analysis, delineating key features for system expansion into PMS, WMS, SCM, etc., and crafting a strategic roadmap for feature distribution across overlapping functionalities.- Designed and implemented agent-based and multi-agent systems utilizing RAG (Retrieval-Augmented Generation) with database integration capabilities, ensuring efficient data retrieval and analysis for decision-making processes.- Described a system feature that enables data forecasting using statistical methods (WMA, Exp.Smoothing) and ML (LR, ARIMA, RF). This functionality was applied for:- - KPI monitoring, including forecasting key indicators at the end of the accounting period.- - Forecasting demand and inventory levels of ingredients in warehouses, ensuring efficient inventory management.As a Business Analyst and Data Specialist, I've leveraged my expertise in Python, SQL, and OpenAI's API to drive company profitability through meticulous data analysis and process optimization.\\nHere's a snapshot of my core accomplishments:\\n- Conducted a comprehensive CRM system analysis, delineating key features for system expansion into PMS, WMS, SCM, etc., and crafting a strategic roadmap for feature distribution across overlapping functionalities.\\n- Designed and implemented agent-based and multi-agent systems utilizing RAG (Retrieval-Augmented Generation) with database integration capabilities, ensuring efficient data retrieval and analysis for decision-making processes.\\n- Described a system feature that enables data forecasting using statistical methods (WMA, Exp.Smoothing) and ML (LR, ARIMA, RF). This functionality was applied for:\\n - - KPI monitoring, including forecasting key indicators at the end of the accounting period.\\n - - Forecasting demand and inventory levels of ingredients in warehouses, ensuring efficient inventory management.\",\n",
       "   'skills': 'Skills:Forecasting ¬∑ Large Language Models (LLM) ¬∑ Python ¬∑ Business Analytics ¬∑ Business Intelligence (BI) ¬∑ Artificial Intelligence (AI) ¬∑ Prompt Engineering ¬∑ Data Visualization (DataViz) ¬∑ Demand ForecastingSkills:Forecasting ¬∑ Large Language Models (LLM) ¬∑ Python ¬∑ Business Analytics ¬∑ Business Intelligence (BI) ¬∑ Artificial Intelligence (AI) ¬∑ Prompt Engineering ¬∑ Data Visualization (DataViz) ¬∑ Demand Forecasting'},\n",
       "  {'company': 'AlderaSoft ',\n",
       "   'position': 'Senior AnalystSenior Analyst',\n",
       "   'workin_period': 'Aug 2022 - Mar 2023 ',\n",
       "   'duration': ' 8 mos',\n",
       "   'description': 'As a System Analyst, I have effectively contributed to various projects including the development of an ETL system, advanced data visualization analytics tools, production calculators, PMS (property management system) for hotels, and applications featuring video content viewing functions.My key responsibilities in these projects included developing a project concept through a conceptual model (BPMN), outlining the main functions of the system (user story) and developing detailed specifications such as use cases, functional and non-functional requirements along with UML diagrams. I was also involved in prototyping using figma and draw.io, and setting tasks for development while continuously monitoring adherence to acceptance criteria.Throughout my work, I have gained proficiency in several crucial tools such as Swagger, Postman, Jira, Confluence, YandexTracker, YandexWiki and more.As a System Analyst, I have effectively contributed to various projects including the development of an ETL system, advanced data visualization analytics tools, production calculators, PMS (property management system) for hotels, and applications featuring video content viewing functions.\\nMy key responsibilities in these projects included developing a project concept through a conceptual model (BPMN), outlining the main functions of the system (user story) and developing detailed specifications such as use cases, functional and non-functional requirements along with UML diagrams. I was also involved in prototyping using figma and draw.io, and setting tasks for development while continuously monitoring adherence to acceptance criteria.\\nThroughout my work, I have gained proficiency in several crucial tools such as Swagger, Postman, Jira, Confluence, YandexTracker, YandexWiki and more.',\n",
       "   'skills': 'N/A'},\n",
       "  {'company': 'Gazpromneft - Vostok ',\n",
       "   'position': 'Petroleum Engineer | Chief Concept EngineerPetroleum Engineer | Chief Concept Engineer',\n",
       "   'workin_period': 'May 2018 - Aug 2022 ',\n",
       "   'duration': ' 4 yrs 4 mos',\n",
       "   'description': \"The key task is the technical and economic assessment of the company's new assets, including: conceptual design, development of asset infrastructure, assessment of capital and operating costs, formation of a financial and economic model, presentation of results on key production and economic indicators.Duties:‚Ä¢\\tConceptual design of development and infrastructure facilities - the conceptual design of one of the licensed blocks allowed to reduce costs by $4 million through the use of an optimal gathering system;‚Ä¢\\tFeasibility study of new (alternative) development options;‚Ä¢\\tCollection of data on forecast production indicators and capital investments of the company in ERA:ISKRA;‚Ä¢\\tAnalysis of changes in forecast indicators (KPI) - developed an Excel macro file using VBA, which allows, taking into account the variability of the initial data, to evaluate the KPI of the project, sensitivity analysis, which reduced the time for preparing similar reports and making decisions by 80%;‚Ä¢\\tCost engineering;‚Ä¢\\tPreparing a presentation report (including presentation to foreign shareholders).The key task is the technical and economic assessment of the company's new assets, including: conceptual design, development of asset infrastructure, assessment of capital and operating costs, formation of a financial and economic model, presentation of results on key production and economic indicators.\\n\\nDuties:\\n‚Ä¢\\tConceptual design of development and infrastructure facilities - the conceptual design of one of the licensed blocks allowed to reduce costs by $4 million through the use of an optimal gathering system;\\n‚Ä¢\\tFeasibility study of new (alternative) development options;\\n‚Ä¢\\tCollection of data on forecast production indicators and capital investments of the company in ERA:ISKRA;\\n‚Ä¢\\tAnalysis of changes in forecast indicators (KPI) - developed an Excel macro file using VBA, which allows, taking into account the variability of the initial data, to evaluate the KPI of the project, sensitivity analysis, which reduced the time for preparing similar reports and making decisions by 80%;\\n‚Ä¢\\tCost engineering;\\n‚Ä¢\\tPreparing a presentation report (including presentation to foreign shareholders).\",\n",
       "   'skills': 'Skills:Financial Modeling ¬∑ Forecasting ¬∑ Oil and Gas Engineering ¬∑ Oil & Gas ¬∑ Presentation Skills ¬∑ VBA ¬∑ Data Visualization (DataViz) ¬∑ Demand ForecastingSkills:Financial Modeling ¬∑ Forecasting ¬∑ Oil and Gas Engineering ¬∑ Oil & Gas ¬∑ Presentation Skills ¬∑ VBA ¬∑ Data Visualization (DataViz) ¬∑ Demand Forecasting'},\n",
       "  {'company': 'SSP Software ',\n",
       "   'position': 'Business System AnalystBusiness System Analyst',\n",
       "   'workin_period': 'Jan 2017 - Apr 2018 ',\n",
       "   'duration': ' 1 yr 4 mos',\n",
       "   'description': 'I was engaged in —Åollection and preparation of analytics for an automated information system for managing field data and production processes in oil, gas and gas condensate fields..Duties:‚Ä¢\\tInteraction with Customers to collect requirements for the system (business trips, conducting face-to-face surveys of work processes and their description, etc.);‚Ä¢\\tDescription and comparative analysis of the results obtained;‚Ä¢\\tFormation of requirements, user scenarios and a unified solution for the functions of the developed System;‚Ä¢\\tElaboration of methods and algorithms of the System functions (calculation of the optimal technological regime, analysis of the Field Development Plan, selection of wells for geological and technical operations, drawing up a research and well workover plan, etc.);‚Ä¢\\tCarrying out the necessary recalculations within the System, taking into account the conducted studies (flow testing, gas condensate studies, field geophysical tests, deep measurements) and PVT studies (EoS, Black Oil);‚Ä¢\\tInteraction with a team of programmers and coordination of the implementation of work stages;‚Ä¢\\tAnalysis of system operation errors and search for their solution;‚Ä¢\\tWriting reports, specifications and component technical specifications;‚Ä¢\\tTesting of the System with subsequent demonstration and thesis defense for the Customer.I was engaged in —Åollection and preparation of analytics for an automated information system for managing field data and production processes in oil, gas and gas condensate fields..\\n\\nDuties:\\n‚Ä¢\\tInteraction with Customers to collect requirements for the system (business trips, conducting face-to-face surveys of work processes and their description, etc.);\\n‚Ä¢\\tDescription and comparative analysis of the results obtained;\\n‚Ä¢\\tFormation of requirements, user scenarios and a unified solution for the functions of the developed System;\\n‚Ä¢\\tElaboration of methods and algorithms of the System functions (calculation of the optimal technological regime, analysis of the Field Development Plan, selection of wells for geological and technical operations, drawing up a research and well workover plan, etc.);\\n‚Ä¢\\tCarrying out the necessary recalculations within the System, taking into account the conducted studies (flow testing, gas condensate studies, field geophysical tests, deep measurements) and PVT studies (EoS, Black Oil);\\n‚Ä¢\\tInteraction with a team of programmers and coordination of the implementation of work stages;\\n‚Ä¢\\tAnalysis of system operation errors and search for their solution;\\n‚Ä¢\\tWriting reports, specifications and component technical specifications;\\n‚Ä¢\\tTesting of the System with subsequent demonstration and thesis defense for the Customer.',\n",
       "   'skills': 'Skills:Business Analysis ¬∑ Data Analysis ¬∑ Oil & Gas ¬∑ Business Analytics ¬∑ Demand ForecastingSkills:Business Analysis ¬∑ Data Analysis ¬∑ Oil & Gas ¬∑ Business Analytics ¬∑ Demand Forecasting'},\n",
       "  {'company': 'Siam-Engineering ',\n",
       "   'position': 'Reservoir EngineerReservoir Engineer',\n",
       "   'workin_period': 'Nov 2012 - Jan 2017 ',\n",
       "   'duration': ' 4 yrs 3 mos',\n",
       "   'description': 'The key task was a comprehensive analysis of the current state of oil field development, identifying candidate wells and the selection of measures to increase oil recovery and stimulate wells.Duties:‚Ä¢\\tAnalysis of the current state of field development, including analysis of the reasons for the decline in oil production, changes in reservoir pressure, determination of the causes of water cut in wells;‚Ä¢\\tIssuance of recommendations for the study and repair of wells;‚Ä¢\\tOptimization of the field development system;‚Ä¢\\tOil depletion analysis;‚Ä¢\\tAnalytical calculations of the effectiveness of geological and technical measures.The key task was a comprehensive analysis of the current state of oil field development, identifying candidate wells and the selection of measures to increase oil recovery and stimulate wells.\\n\\nDuties:\\n‚Ä¢\\tAnalysis of the current state of field development, including analysis of the reasons for the decline in oil production, changes in reservoir pressure, determination of the causes of water cut in wells;\\n‚Ä¢\\tIssuance of recommendations for the study and repair of wells;\\n‚Ä¢\\tOptimization of the field development system;\\n‚Ä¢\\tOil depletion analysis;\\n‚Ä¢\\tAnalytical calculations of the effectiveness of geological and technical measures.',\n",
       "   'skills': 'Skills:Oil and Gas Engineering ¬∑ Oil & Gas ¬∑ Presentation Skills ¬∑ Reservoir Engineering ¬∑ VBA ¬∑ Data Visualization (DataViz)Skills:Oil and Gas Engineering ¬∑ Oil & Gas ¬∑ Presentation Skills ¬∑ Reservoir Engineering ¬∑ VBA ¬∑ Data Visualization (DataViz)'},\n",
       "  {'company': '–°–∏–±–∏—Ä—Å–∫–∞—è –°–µ—Ä–≤–∏—Å–Ω–∞—è –ö–æ–º–ø–∞–Ω–∏—è ',\n",
       "   'position': 'Chief Engineer | Well Completion EngineerChief Engineer | Well Completion Engineer',\n",
       "   'workin_period': 'Jan 2011 - Nov 2012 ',\n",
       "   'duration': ' 1 yr 11 mos',\n",
       "   'description': '‚Ä¢\\tTechnological support for cementing directional, horizontal wells;‚Ä¢\\tTechnological support for cementing sidetracks (liners);‚Ä¢\\tPreparation of documents on the well cementing report;‚Ä¢\\tDrawing up well cementing programs;‚Ä¢\\tProtection of reports to the Customer.‚Ä¢\\tTechnological support for cementing directional, horizontal wells;\\n‚Ä¢\\tTechnological support for cementing sidetracks (liners);\\n‚Ä¢\\tPreparation of documents on the well cementing report;\\n‚Ä¢\\tDrawing up well cementing programs;\\n‚Ä¢\\tProtection of reports to the Customer.',\n",
       "   'skills': 'Skills:Oil & GasSkills:Oil & Gas'},\n",
       "  {'company': 'Imperial Energy ',\n",
       "   'position': 'Field Operator | Oil and Gas Production EngineerField Operator | Oil and Gas Production Engineer',\n",
       "   'workin_period': 'Aug 2009 - Dec 2010 ',\n",
       "   'duration': ' 1 yr 5 mos',\n",
       "   'description': '‚Ä¢\\tMaintenance of the technological process for all methods of oil, gas and gas condensate production;‚Ä¢\\tImplementation of work to maintain the specified operating mode of wells, group metering units and other facilities related to the technology of oil, gas and gas condensate production;‚Ä¢\\tMaintenance of well communications;‚Ä¢\\tEquipment metering.‚Ä¢\\tMaintenance of the technological process for all methods of oil, gas and gas condensate production;\\n‚Ä¢\\tImplementation of work to maintain the specified operating mode of wells, group metering units and other facilities related to the technology of oil, gas and gas condensate production;\\n‚Ä¢\\tMaintenance of well communications;\\n‚Ä¢\\tEquipment metering.',\n",
       "   'skills': 'Skills:Oil and Gas Engineering ¬∑ Oil & GasSkills:Oil and Gas Engineering ¬∑ Oil & Gas'}],\n",
       " 'Education': [{'university': 'Heriot-Watt University',\n",
       "   'degree': 'Master of Science (MSc), Petroleum Engineering',\n",
       "   'dates': '2015 - 2016',\n",
       "   'details': ['Activities and societies: Participant of the best Field Development Project (1st place)',\n",
       "    'Graduation thesis: ‚ÄúUncertainty reduction of drilling wells at the Field A‚Äù',\n",
       "    'Skills: Oil and Gas Engineering ¬∑ Reservoir Engineering ¬∑ Oil & Gas',\n",
       "    'Diploma'],\n",
       "   'certificates': ['Heriot-Watt University', 'Diploma']},\n",
       "  {'university': 'Peter the Great St.Petersburg Polytechnic University',\n",
       "   'degree': 'Postgraduate Degree, Intelligent Systems',\n",
       "   'dates': 'Feb 2023 - Jun 2023',\n",
       "   'details': ['Grade: A',\n",
       "    'Activities and societies: - High-level Design of Information Control Systems - Project Management - Corporate Information Systems - Intelligent Systems - Software Development Technologies (ML) - Group Project: Safety Helmet Detection expert system - Individual Project: Modelling the system of Permeate neutralisation plant N1',\n",
       "    'A Group Project goal Develop an expert system for recognizing the wearing of safety helmets based on incoming data (photo) that returns a response within an acceptable time frame and with minimal losses. Tasks: - Create use case, swimlane, IDEF0 diagrams - Choose an appropriate architecture - Train a model (Yolo5, CNN) - Create a telegram bot and apply a chosen model Additionally, completed an individual project modeling high-level and low-level design for the Permeate Neutralisation Plant N1 using UML and CodeSys, enhancing skills in system analysis and automation.',\n",
       "    'Skills: Python ¬∑ Business Analytics',\n",
       "    'Human Machine Interface - Individual Project',\n",
       "    'Application of the models - Group Project',\n",
       "    'Certificate'],\n",
       "   'certificates': ['Peter the Great St.Petersburg Polytechnic University',\n",
       "    'Human Machine Interface - Individual Project',\n",
       "    'Application of the models - Group Project',\n",
       "    'Certificate']},\n",
       "  {'university': 'Tomsk Polytechnic University',\n",
       "   'degree': '–ú–∞–≥–∏—Å—Ç—Ä/ MSc, –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Ñ—Ç—è–Ω—ã—Ö –∏ –≥–∞–∑–æ–≤—ã—Ö –º–µ—Å—Ç–æ—Ä–æ–∂–¥–µ–Ω–∏–π/ Reservoir Engineering',\n",
       "   'dates': '2005 - 2011',\n",
       "   'details': ['Skills: Oil and Gas Engineering ¬∑ Reservoir Engineering'],\n",
       "   'certificates': ['Tomsk Polytechnic University']}],\n",
       " 'Certification': [{'certification_name': 'Build a Machine Learning Model Skill Path',\n",
       "   'issuer': 'Codecademy',\n",
       "   'issue_date': 'Issued Nov 2024',\n",
       "   'credential_id': 'N/A',\n",
       "   'skills': 'Artificial Intelligence (AI) ¬∑ Python',\n",
       "   'certificates_or_media': ['Build a Machine Learning Model Skill Path',\n",
       "    'Certificate | Codecademy.pdf',\n",
       "    'Ml_Capstone_Project at GitHub']},\n",
       "  {'certification_name': 'AI Engineering Specialization',\n",
       "   'issuer': 'Scrimba',\n",
       "   'issue_date': 'Issued Mar 2024',\n",
       "   'credential_id': 'Credential ID GANNTUR4L26C',\n",
       "   'skills': 'Large Language Models (LLM) ¬∑ Artificial Intelligence (AI) ¬∑ Prompt Engineering',\n",
       "   'certificates_or_media': ['AI Engineering Specialization']},\n",
       "  {'certification_name': 'Supply Chain Analytics Specialization',\n",
       "   'issuer': 'Rutgers University',\n",
       "   'issue_date': 'Issued Jan 2024',\n",
       "   'credential_id': 'Credential ID 4LXCK6T92GYY',\n",
       "   'skills': 'Inventory Analysis ¬∑ Demand Forecasting ¬∑ Supply Chain Risk Management ¬∑ Business Analytics ¬∑ Forecasting ¬∑ Supply Chain',\n",
       "   'certificates_or_media': ['Supply Chain Analytics Specialization']},\n",
       "  {'certification_name': 'IBM Data Analyst Specialization',\n",
       "   'issuer': 'IBM',\n",
       "   'issue_date': 'Issued Sep 2022',\n",
       "   'credential_id': 'Credential ID 68VUENLDVVJ5',\n",
       "   'skills': 'Python ¬∑ Data Visualization (DataViz) ¬∑ Microsoft Excel ¬∑ Python Programming ¬∑ Business Intelligence (BI) ¬∑ Data Analysis ¬∑ SQL',\n",
       "   'certificates_or_media': ['IBM Data Analyst Specialization']},\n",
       "  {'certification_name': 'Google Project Management: Specialization',\n",
       "   'issuer': 'Google',\n",
       "   'issue_date': 'Issued May 2022',\n",
       "   'credential_id': 'Credential ID EQDFTKPMCPVT',\n",
       "   'skills': 'Lean Six Sigma',\n",
       "   'certificates_or_media': ['Google Project Management: Specialization']}],\n",
       " 'Posts': [{'–î–∞—Ç–∞': '6d ‚Ä¢6 days ago',\n",
       "   '–ê–≤—Ç–æ—Ä': 'Egor ZubenkoEgor Zubenko',\n",
       "   '–ö–æ–Ω—Ç–µ–Ω—Ç': 'Build a Machine Learning Model Skill Path fromCodecademy!So, it was useful to refresh my knowledge of regression, classification, and working with PyTorch and scikit-learn.',\n",
       "   '–†–µ–∞–∫—Ü–∏–∏': '9Maksim Stepura and 8 others',\n",
       "   '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': '1 comment',\n",
       "   '–†–µ–ø–æ—Å—Ç—ã': '0',\n",
       "   '–í–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è': 'N/A'},\n",
       "  {'–î–∞—Ç–∞': '1mo ‚Ä¢1 month ago',\n",
       "   '–ê–≤—Ç–æ—Ä': 'Egor ZubenkoEgor Zubenko',\n",
       "   '–ö–æ–Ω—Ç–µ–Ω—Ç': 'It really sounds interesting ))\"\"\"Based on our interactions, it seems you have a strong interest in data analysis, AI systems, cryptography, and project management. A career path you might enjoy, which perhaps hasn‚Äôt crossed your mind, could be **AI Product Manager or AI Solutions Architect**.Here‚Äôs why:1. **AI Product Manager**: You already work with advanced analytics, machine learning, and agent-based systems like LangGraph and CrewAI. This role would allow you to combine your deep understanding of data, product development, and market trends. You‚Äôd focus on developing AI-driven products that optimize workflows, which aligns well with your interest in call center automation and optimizing operator efficiency.2. **AI Solutions Architect**: This position would involve designing and implementing AI systems tailored to specific business needs. Given your experience with automation projects, especially in logistics and call centers, you‚Äôd excel in crafting custom AI models that solve practical problems in CPA marketing or supplement production logistics.Both of these roles combine your technical expertise with strategic planning, and they allow you to leverage your knowledge of emerging technologies, particularly in AI and blockchain, to drive innovation within businesses.Does this path spark any new interest or ideas for you?\"\"\"‚Ä¶more',\n",
       "   '–†–µ–∞–∫—Ü–∏–∏': '2Maksim Stepura and 1 other',\n",
       "   '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': '1 comment',\n",
       "   '–†–µ–ø–æ—Å—Ç—ã': '0',\n",
       "   '–í–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è': 'N/A'},\n",
       "  {'–î–∞—Ç–∞': '8mo ‚Ä¢9 months ago',\n",
       "   '–ê–≤—Ç–æ—Ä': 'Egor ZubenkoEgor Zubenko',\n",
       "   '–ö–æ–Ω—Ç–µ–Ω—Ç': 'I‚Äôm happy to share that I‚Äôve obtained the AI Engineering course fromScrimbaand highly (!) recommend it.It gives not only theoretical knowledge but also practical skills in AI application development. The instructors and course materials are top! This course is beneficial for anyone looking to dive deeper into AI.P.S. I also had to start learning JavaScript from scratch to fully engage with the course content )))hashtag#LLMhashtag#AIEngineeringhashtag#ArtificialIntelligence‚Ä¶more',\n",
       "   '–†–µ–∞–∫—Ü–∏–∏': '9',\n",
       "   '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': '6 comments',\n",
       "   '–†–µ–ø–æ—Å—Ç—ã': '0',\n",
       "   '–í–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è': 'N/A'},\n",
       "  {'–î–∞—Ç–∞': '8mo ‚Ä¢9 months ago',\n",
       "   '–ê–≤—Ç–æ—Ä': 'Egor ZubenkoEgor Zubenko',\n",
       "   '–ö–æ–Ω—Ç–µ–Ω—Ç': 'Hello!While working on a new feature of the system, I encountered a problem that I do not yet understand how to solve.So, there is a database that will be regularly updated and expanded with new content. Vectors are created using OpenAI tools (embedding), they are then saved in the database along with functionality for searching for similar vectors.‚ùìThe question itself is: How can we effectively maintain the relevance of these vectors, minimizing the need for their constant recalculation when changes are made to the content? Is it possible to use metadata, for example, by adding a timestamp to it?The structure of the table in the database is as follows:- id: a unique document identifier.- content: textual content of the document (in my case - chunk).- metadata: document metadata in JSONB format.- embedding: vector representation of the document with a dimension of 1536.‚Ä¶more',\n",
       "   '–†–µ–∞–∫—Ü–∏–∏': '2',\n",
       "   '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': '0',\n",
       "   '–†–µ–ø–æ—Å—Ç—ã': '0',\n",
       "   '–í–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è': 'N/A'},\n",
       "  {'–î–∞—Ç–∞': '1yr ‚Ä¢1 year ago',\n",
       "   '–ê–≤—Ç–æ—Ä': 'Egor ZubenkoEgor Zubenko',\n",
       "   '–ö–æ–Ω—Ç–µ–Ω—Ç': \"üéì Excited to announce that I've completed the Supply Chain Management Specialization byCourseraandRutgers Universityof New Jersey! üöÄ Studying onCourseraoffered a cool opportunity to expand skills while diving deeper into industries I work with. Looking forward to implementing this new knowledge in developing SCM systems!hashtag#SupplyChainManagementhashtag#LifelongLearnerhashtag#Courserahashtag#RutgersUniversity‚Ä¶more\",\n",
       "   '–†–µ–∞–∫—Ü–∏–∏': '14',\n",
       "   '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏': '2 comments',\n",
       "   '–†–µ–ø–æ—Å—Ç—ã': '0',\n",
       "   '–í–ø–µ—á–∞—Ç–ª–µ–Ω–∏—è': 'N/A'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#********** CHECK THE RESULT *************\n",
    "\n",
    "profile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d4a9770-3222-4a39-aca6-6de939f892c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–∫—Ä—ã–≤–∞–µ–º –¥—Ä–∞–π–≤–µ—Ä\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9553d847-720a-4c11-8f41-a80a56c7bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = \"profile_data.json\"\n",
    "\n",
    "\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(profile_data, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7f741e-e785-4ef9-9195-e584a5f97eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
